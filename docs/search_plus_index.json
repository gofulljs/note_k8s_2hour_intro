{"./":{"url":"./","title":"Kubernetes 课程导读","keywords":"","body":"k8s 课程导读 a note use gitbook for Kubernetes 二小时入门教程, 根据自己的学习会做一些添加和补充, 防止羽雀又崩了, 2023-10-23 崩过 😂 B 站视频地址 https://www.bilibili.com/video/BV1k24y197KC 原文档地址 https://www.yuque.com/wukong-zorrm/qdoy5p 为什么 Kubernetes 学起来很难？ zh Kubernetes 本身比较复杂，组件众多，安装过程比较麻烦 本课程使用 K3s 快速创建学习环境，不要把时间和精力浪费在搭环境上 网络问题，许多谷歌镜像或软件仓库访问不到，拉取失败 配置阿里云镜像加速 手动拉取镜像、手动导出、导入镜像 Kubernetes 版本有重大变化，网上好多教程已过时 kubernetes 从 1.24 版本开始，移除了对 docker 的支持 本课程采用 1.25 版本，使用 containerd 作为容器运行时 课程中对 containerd 用法以及可能遇到的问题进行了说明 官方文档有错误，许多例子或命令运行不起来 本课程会帮你避过官方文档中的坑 很多教程只有例子，没有实战，导致“一学就会，一用就废” 本课程会演示常用中间件的安装（MySQL 主从集群、Redis 主从集群） 本课程会演示如何在 K8s 上运行一个完整的应用 应用程序包括前端(node/nginx)、缓存(redis)、数据库(mysql)、后端(java） "},"base/":{"url":"base/","title":"Kubernetes 基础","keywords":"","body":""},"base/intro.html":{"url":"base/intro.html","title":"Kubernetes 简介","keywords":"","body":"Kubernetes 简介 简介 Kubernetes 是一个开源的容器编排引擎和容器集群管理工具，用来对容器化应用进行自动化部署、 扩缩和管理。 Kubernetes 这个名字源于希腊语，意为“舵手”或“飞行员”。k8s 这个缩写是因为 k 和 s 之间有 8 个字符。 Google 在 2014 年开源了 Kubernetes 项目。 优势 Kubernetes 建立在 Google 大规模运行生产工作负载十几年经验的基础上， 结合了社区中最优秀的想法和实践。它之所以能够迅速流行起来，是因为它的许多功能高度契合互联网大厂的部署和运维需求。 Kubernetes 可以提供： 服务发现和负载均衡 Kubernetes 可以使用 DNS 名称或自己的 IP 地址来曝露容器。 如果进入容器的流量很大 Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。 存储编排 Kubernetes 允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。 自动部署和回滚 你可以使用 Kubernetes 描述已部署容器的所需状态， 它可以以受控的速率将实际状态更改为期望状态。 例如，你可以自动化 Kubernetes 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。也可以是方便的实现金丝雀部署(canary deployment )。 自动完成装箱计算 你为 Kubernetes 提供许多节点组成的集群，在这个集群上运行容器化的任务。 你告诉 Kubernetes 每个容器需要多少 CPU 和内存 (RAM)。 Kubernetes 可以将这些容器按实际情况调度到你的节点上，以最佳方式利用你的资源。 自我修复 Kubernetes 将重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器， 并且在准备好服务之前不将其通告给客户端。 密钥与配置管理 ubernetes 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。 云原生 2015 年由 Google、Redhat 等大型云计算厂商以及一些开源公司共同牵头成立了 Cloud Native Computing Foundation（云原生计算基金会）。 云原生计算基金会（CNCF）致力于培育和维护一个厂商中立的开源生态系统，来推广云原生技术。 云原生的概念从此广泛传播。 云原生定义 Kubernetes 是 CNCF 托管的第一个开源项目。因此现在提到云原生，往往我们都把它与 kubernetes 联系起来。 通俗解释 使用 Java、Go、PHP、Python 等语言开发的应用我们称之为原生应用，在设计和开发这些应用时，使他们能够运行在云基础设施(或 kubernetes)上，从而使应用具备可弹性扩展的能力，我们称之为云原生应用。我们可以将云原生理解为以容器技术为载体、基于微服务架构思想的一套技术体系和方法论。 官方定义 云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API。 这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。 微服务 在 Kubernetes 之前，Pivotal（开源 Java 开发框架 Spring 的母公司，后被 VMware 收购）是云原生应用的提出者，并推出了 Pivotal Cloud Foundry 云原生应用平台和 Spring Cloud 开发框架，成为云原生应用架构中先驱者和探路者。Spring Cloud 通过微服务架构，使程序具备可拓展性和在分布式环境运行的能力。Spring Cloud 和 Kubernetes 有很多功能是重合的，例如： 服务注册和发现 API 网关 负载均衡 配置管理 但是 Spring Cloud 只能用于 Java 应用开发，而 kubernetes 是语言无关的，可以用于各种语言开发的应用。 文档参考:https://kubernetes.io/zh-cn/docs/concepts/overview/ https://github.com/cncf/toc/blob/main/DEFINITION.md "},"base/architecture.html":{"url":"base/architecture.html","title":"Kubernetes 架构","keywords":"","body":"kubernetes 架构 kubernetes 架构 一个 Kubernetes 集群至少包含一个控制平面(control plane)，以及一个或多个工作节点(worker node)。 控制平面(Control Plane) : 控制平面负责管理工作节点和维护集群状态。所有任务分配都来自于控制平面。 工作节点(Worker Node) : 工作节点负责执行由控制平面分配的请求任务,运行实际的应用和工作负载。 控制平面 控制平面组件会为集群做出全局决策，比如资源的调度、检测和响应集群事件。 kube-apiserver 如果需要与 Kubernetes 集群进行交互，就要通过 API。 apiserver是 Kubernetes 控制平面的前端，用于处理内部和外部请求。 kube-scheduler 集群状况是否良好？如果需要创建新的容器，要将它们放在哪里？这些是调度程序需要关注的问题。 scheduler调度程序会考虑容器集的资源需求（例如 CPU 或内存）以及集群的运行状况。随后，它会将容器集安排到适当的计算节点。 etcd etcd 是一个键值对数据库，用于存储配置数据和集群状态信息。 kube-controller-manager 控制器负责实际运行集群，controller-manager 控制器管理器则是将多个控制器功能合而为一，降低了程序的复杂性。 controller-manager 包含了这些控制器： 节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应 任务控制器（Job Controller）：监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成 端点控制器（Endpoints Controller）：填充端点（Endpoints）对象（即加入 Service 与 Pod） 服务帐户和令牌控制器（Service Account & Token Controllers）：为新的命名空间创建默认帐户和 API 访问令牌 Node 组件 节点组件会在每个节点上运行，负责维护运行的 Pod 并提供 Kubernetes 运行环境。 kubelet kubelet 会在集群中每个节点（node）上运行。 它保证容器（containers）都运行在 Pod 中。 当控制平面需要在节点中执行某个操作时，kubelet 就会执行该操作。 kube-proxy kube-proxy 是集群中每个节点（node）上运行的网络代理，是实现 Kubernetes 服务（Service） 概念的一部分。 kube-proxy 维护节点网络规则和转发流量，实现从集群内部或外部的网络与 Pod 进行网络通信。 容器运行时（Container Runtime） 这个基础组件使 Kubernetes 能够有效运行容器。 它负责管理 Kubernetes 环境中容器的执行和生命周期。 Kubernetes 支持许多容器运行环境，例如 containerd、 docker 以及 Kubernetes CRI (容器运行环境接口) 的其他任何实现。 组件关系 cloud-controller-manager 控制平面还包含一个可选组件cloud-controller-manager。 云控制器管理器（Cloud Controller Manager）允许你将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。 如果在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的集群不需要有云控制器管理器。 参考资料：https://kubernetes.io/zh-cn/docs/concepts/overview/components/ https://www.redhat.com/zh/topics/containers/kubernetes-architecture "},"base/minikube.html":{"url":"base/minikube.html","title":"安装 Minikube","keywords":"","body":"安装 Minikube docker-desktop 新版本自带了 kubenetes, 不需要使用 minikube 了。 自带的安装较慢可以使用 https://github.com/AliyunContainerService/k8s-for-docker-desktop 去安装 kubenetes 和 dashboard dashbord https://github.com/kubernetes/dashboard 安装官方控制台 kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml 查看是否允许成功 $ kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-5d78c9869d-tjhgv 1/1 Running 5 (7m45s ago) 2d22h kube-system coredns-5d78c9869d-vbzjn 1/1 Running 5 (7m45s ago) 2d22h kube-system etcd-docker-desktop 1/1 Running 5 (7m49s ago) 2d22h kube-system kube-apiserver-docker-desktop 1/1 Running 5 (7m40s ago) 2d22h kube-system kube-controller-manager-docker-desktop 1/1 Running 5 (7m50s ago) 2d22h kube-system kube-proxy-nrmkx 1/1 Running 5 (7m50s ago) 2d22h kube-system kube-scheduler-docker-desktop 1/1 Running 5 (7m50s ago) 2d22h kube-system storage-provisioner 1/1 Running 9 (6m28s ago) 2d22h kube-system vpnkit-controller 1/1 Running 5 (7m50s ago) 2d22h kubernetes-dashboard dashboard-metrics-scraper-5cb4f4bb9c-ws8sk 1/1 Running 1 (7m50s ago) 11m kubernetes-dashboard kubernetes-dashboard-6967859bff-5tvh6 1/1 Running 1 (7m50s ago) 11m 以上后 2 行出现代表成功 启用 dashboard kubectl proxy kubectl 会使得 Dashboard 可以通过 http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ 访问。 UI 只能 通过执行这条命令的机器进行访问。 以上需要访问令牌 参考 https://github.com/AliyunContainerService/k8s-for-docker-desktop 部署访问令牌 授权 kube-system 默认服务账号 kubectl apply -f https://raw.githubusercontent.com/AliyunContainerService/k8s-for-docker-desktop/master/kube-system-default.yaml 获取 token windows $TOKEN=((kubectl -n kube-system describe secret default | Select-String \"token:\") -split \" +\")[1] kubectl config set-credentials docker-desktop --token=\"${TOKEN}\" echo $TOKEN or linux TOKEN=$(kubectl -n kube-system describe secret default| awk '$1==\"token:\"{print $2}') kubectl config set-credentials docker-desktop --token=\"${TOKEN}\" echo $TOKEN 生成好后在以下路径 powershell: %UserProfile%\\.kube\\config or sh: $HOME/.kube/config "},"base/env_k3s.html":{"url":"base/env_k3s.html","title":"使用 K3s 快速搭建集群","keywords":"","body":"使用 K3s 快速搭建集群 提示： 1.本课程基于kubernetes V1.25版本。提示： 2.从V1.24开始，kubernetes默认容器运行时使用containerd，不再使用docker。 为什么使用 K3s K3s 是一个轻量级的、完全兼容的 Kubernetes 发行版本。非常适合初学者。 K3s 将所有 Kubernetes 控制平面组件都封装在单个二进制文件和进程中，文件大小 提示： K3s完全兼容kubernetes，二者的操作是一样的，使用k3s完全满足我们学习kubernetes的要求，课程的最后，我们再使用kubeadm安装一个完整的集群。 离线安装 K3s 集群 K3s 集群分为 k3s Server(控制平面)和 k3s Agent(工作节点)。所有的组件都打包在单个二进制文件中。 运行环境 最低运行要求 内存: 512MB / CPU: 1 核心 K3s 版本：v1.25.0+k3s1 集群规划 主机名 IP 地址 配置 系统 网络 k8s-master 192.168.56.109 内存：2GCPU：2核硬盘：20G CentOS7.9.2009最小化安装 互联网:NAT网络内部网络: Host-only k8s-worker1 192.168.56.111 k8s-worker2 192.168.56.112 ps 每个主机需要设置 hostname k8s-master hostnamectl set-hostname k8s-master k8s-worker # k8s-worker1 hostnamectl set-hostname k8s-worker1 # k8s-worker2 hostnamectl set-hostname k8s-worker2 1.准备工作 需要在每台机器上执行如下命令： 关闭防火墙 设置 selinux(需要联网) systemctl disable firewalld --now yum install -y container-selinux selinux-policy-base yum install -y https://rpm.rancher.io/k3s/latest/common/centos/7/noarch/k3s-selinux-0.2-1.el7_8.noarch.rpm 2.下载安装包 下载安装脚本 install.sh：https://get.k3s.io/ 下载 k3s 二进制文件：k3s 下载必要的 image：离线安装需要的 image 文件 这些文件都可以在github仓库中获取：https://github.com/k3s-io/k3s 3.执行安装脚本 将k3s二进制文件移动到/usr/local/bin 目录，并添加执行权限 mv k3s /usr/local/bin chmod +x /usr/local/bin/k3s 将镜像移动到/var/lib/rancher/k3s/agent/images/目录（无需解压） mkdir -p /var/lib/rancher/k3s/agent/images/ cp ./k3s-airgap-images-amd64.tar.gz /var/lib/rancher/k3s/agent/images/ 在k8s-master节点执行： #修改权限 chmod +x install.sh #离线安装 INSTALL_K3S_SKIP_DOWNLOAD=true ./install.sh #安装完成后，查看节点状态 kubectl get node #查看token cat /var/lib/rancher/k3s/server/node-token #K10c4b79481685b50e4bca2513078f4e83b62d1d0b5f133a8a668b65c8f9249c53e::server:bf7b63be7f3471838cbafa12c1a1964d 在k8s-worker1和k8s-worker2节点执行 INSTALL_K3S_SKIP_DOWNLOAD=true \\ K3S_URL=https://192.168.56.109:6443 \\ K3S_TOKEN=K1012bdc3ffe7a5d89ecb125e56c38f9fe84a9f9aed6db605f7698fa744f2f2f12f::server:fdf33f4921dd607cadf2ae3c8eaf6ad9 \\ ./install.sh 排查错误 如果安装或启动不成功，可能有以下几个原因： 1. 时间不统一 2. IP有冲突，请为每个主机分配不同的IP 3. 主机名(hostname)重复，请为每个主机设置不同的主机名 4. 网卡的MAC有冲突，复制虚拟机时，请为所有网卡重新生产MAC地址 参考文档： https://k3s.io/ https://rancher.com/docs/k3s/latest/en/ https://rancher.com/docs/k3s/latest/en/quick-start/ https://rancher.com/docs/k3s/latest/en/installation/airgap/ "},"base/pod.html":{"url":"base/pod.html","title":"Pod(容器集)","keywords":"","body":"Pod(容器集) Pod Pod 是包含一个或多个容器的容器组，是 Kubernetes 中创建和管理的最小对象。 Pod 有以下特点： Pod 是 kubernetes 中 最小的调度单位（原子单元），Kubernetes 直接管理 Pod 而不是容器。 同一个 Pod 中的容器总是会被自动安排到集群中的 同一节点（物理机或虚拟机）上，并且一起调度。 Pod 可以理解为运行特定应用的“逻辑主机”，这些容器共享存储、网络和配置声明(如资源限制)。 每个 Pod 有唯一的 IP 地址。 IP 地址分配给 Pod，在同一个 Pod 内，所有容器共享一个 IP 地址和端口空间，Pod 内的容器可以使用 localhost 互相通信。 例如，你可能有一个容器，为共享卷中的文件提供 Web 服务器支持，以及一个单独的 \"边车 (sidercar)\" 容器负责从远端更新这些文件，如下图所示： 创建和管理 Pod # 创建 mynginx pod 并使用容器镜像 nginx 的 1.22 版本 kubectl run mynginx --image=nginx:1.22 # 查看Pod kubectl get pod # 查看pod日志 kubectl logs -f mynginx # 查看pod描述信息 kubectl describe pod mynginx 访问 pod # 查看Pod详细信息(包含IP和运行节点信息) $ kubectl get pod -owide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES mynginx 1/1 Running 0 14m 10.42.2.5 k3d-demo-server-0 获取到访问的内容 # 使用Pod的ip+pod里面运行容器的端口 curl 10.42.2.5 # 或使用 wget wget -qO- http://10.42.2.5 容器中执行命令 #在容器中执行 kubectl exec mynginx -it -- /bin/bash #进入容器访问自身 curl localhost 运行 pod，退出后自动删除容器 # 运行 busybox 容器 kubectl run my-busybox --image=busybox -ti --rm # ping 主机ip ping {{host_ip}} # 退出 exit # 发现 pod 已不存在 kubectl get pod 删除容器 # 删除 mynginx kubectl delete pod mynginx # 强制删除 kubectl delete pod mynginx --force watch 模式 kubectl get pod --watch 镜像加速 由于 kubernetes 从V1.24版本开始默认使用containerd，需要修改containerd的配置文件，才能让 Pod 的镜像使用镜像加速器。 配置文件路径一般为/etc/containerd/config.toml，详见阿里云镜像加速。 在 K3s 中配置镜像仓库 K3s 会自动生成 containerd 的配置文件/var/lib/rancher/k3s/agent/etc/containerd/config.toml,不要直接修改这个文件，k3s 重启后修改会丢失。 为了简化配置，K3s 通过/etc/rancher/k3s/registries.yaml文件来配置镜像仓库，K3s 会在启动时检查这个文件是否存在。 我们需要在每个节点上新建/etc/rancher/k3s/registries.yaml文件，配置内容如下： mirrors: docker.io: endpoint: - \"https://fsp2sfpr.mirror.aliyuncs.com/\" 重启每个节点 systemctl restart k3s systemctl restart k3s-agent 查看配置是否生效。 cat /var/lib/rancher/k3s/agent/etc/containerd/config.toml 容器与镜像 容器运行时接口（CRI） Kubelet 运行在每个节点(Node)上,用于管理和维护 Pod 和容器的状态。 容器运行时接口（CRI）是 kubelet 和容器运行时之间通信的主要协议。它将 Kubelet 与容器运行时解耦，理论上，实现了 CRI 接口的容器引擎，都可以作为 kubernetes 的容器运行时。 Docker没有实现（CRI）接口，Kubernetes使用dockershim来兼容docker。 自V1.24版本起，Dockershim 已从 Kubernetes 项目中移除。 crictl是一个兼容 CRI 的容器运行时命令，他的用法跟 docker 命令一样，可以用来检查和调试底层的运行时容器。 查看容器和镜像 # 查看容器 $ crictl ps CONTAINER IMAGE CREATED STATE NAME ATTEMPT POD ID POD 47aaa00baba1e 0f8498f13f3ad 7 hours ago Running nginx 0 ad79f75bc4e04 nginx-deploy-5964889c54-fkd8t 2c47bdd5aaa26 ead0a4a53df89 3 days ago Running coredns 10 05fbcfa8067b8 coredns-77ccd57875-rf6s4 f1bcf4785b184 af74bd845c4a8 3 days ago Running lb-tcp-443 1 d793ffcccf6fe svclb-traefik-c090484e-cnsgm 2cc1af75acf27 af74bd845c4a8 3 days ago Running lb-tcp-80 1 d793ffcccf6fe svclb-traefik-c090484e-cnsgm # 查看镜像 $ crictl images IMAGE TAG IMAGE ID SIZE docker.io/library/nginx 1.22 0f8498f13f3ad 57MB docker.io/library/nginx 1.23 a7be6198544f0 57MB docker.io/rancher/klipper-helm v0.8.0-build20230510 6f42df210d7fa 95MB docker.io/rancher/klipper-lb v0.4.4 af74bd845c4a8 4.92MB docker.io/rancher/mirrored-coredns-coredns 1.10.1 ead0a4a53df89 16.2MB docker.io/rancher/mirrored-pause 3.6 6270bb605e12e 301kB crictl 命令 命令相对 docker 少一些，比如无法导入导出镜像 $ crictl -h NAME: crictl - client for CRI USAGE: crictl [global options] command [command options] [arguments...] VERSION: v1.26.0-rc.0-k3s1 COMMANDS: attach Attach to a running container create Create a new container exec Run a command in a running container version Display runtime version information images, image, img List images inspect Display the status of one or more containers inspecti Return the status of one or more images imagefsinfo Return image filesystem info inspectp Display the status of one or more pods logs Fetch the logs of a container port-forward Forward local port to a pod ps List containers pull Pull an image from a registry run Run a new container inside a sandbox runp Run a new pod rm Remove one or more containers rmi Remove one or more images rmp Remove one or more pods pods List pods start Start one or more created containers info Display information of the container runtime stop Stop one or more running containers stopp Stop one or more running pods update Update one or more running containers config Get and set crictl client configuration options stats List container(s) resource usage statistics statsp List pod resource usage statistics completion Output shell completion code checkpoint Checkpoint one or more running containers help, h Shows a list of commands or help for one command GLOBAL OPTIONS: --config value, -c value Location of the client config file. If not specified and the default does not exist, the program's directory is searched as well (default: \"/etc/crictl.yaml\") [$CRI_CONFIG_FILE] --debug, -D Enable debug mode (default: false) --image-endpoint value, -i value Endpoint of CRI image manager service (default: uses 'runtime-endpoint' setting) [$IMAGE_SERVICE_ENDPOINT] --runtime-endpoint value, -r value Endpoint of CRI container runtime service (default: uses in order the first successful one of [unix:///run/k3s/containerd/containerd.sock unix:///var/run/dockershim.sock unix:///run/containerd/containerd.sock unix:///run/crio/crio.sock unix:///var/run/cri-dockerd.sock]). Default is now deprecated and the endpoint should be set instead. [$CONTAINER_RUNTIME_ENDPOINT] --timeout value, -t value Timeout of connecting to the server in seconds (e.g. 2s, 20s.). 0 or less is set to default (default: 2s) --help, -h show help (default: false) --version, -v print the version (default: false) 在一些局域网环境下，我们没法通过互联网拉取镜像，可以手动的导出、导入镜像。 crictl 命令没有导出、导入镜像的功能。 需要使用 ctr 命令导出、导入镜像，它是 containerd 的命令行接口。 # 只需要掌握导入导出镜像即可 $ ctr -h NAME: ctr - __ _____/ /______ / ___/ __/ ___/ / /__/ /_/ / \\___/\\__/_/ containerd CLI USAGE: ctr [global options] command [command options] [arguments...] VERSION: v1.7.1-k3s1 DESCRIPTION: ctr is an unsupported debug and administrative client for interacting with the containerd daemon. Because it is unsupported, the commands, options, and operations are not guaranteed to be backward compatible or stable from release to release of the containerd project. COMMANDS: plugins, plugin Provides information about containerd plugins version Print the client and server versions containers, c, container Manage containers content Manage content events, event Display containerd events images, image, i Manage images leases Manage leases namespaces, namespace, ns Manage namespaces pprof Provide golang pprof outputs for containerd run Run a container snapshots, snapshot Manage snapshots tasks, t, task Manage tasks install Install a new package oci OCI tools sandboxes, sandbox, sb, s Manage sandboxes info Print the server info shim Interact with a shim directly help, h Shows a list of commands or help for one command GLOBAL OPTIONS: --debug Enable debug output in logs --address value, -a value Address for containerd's GRPC server (default: \"/run/k3s/containerd/containerd.sock\") [$CONTAINERD_ADDRESS] --timeout value Total timeout for ctr commands (default: 0s) --connect-timeout value Timeout for connecting to containerd (default: 0s) --namespace value, -n value Namespace to use with commands (default: \"k8s.io\") [$CONTAINERD_NAMESPACE] --help, -h show help --version, -v print the version 从docker导出镜像再导入到containerd中 $ docker pull alpine:3.15 $ docker save alpine:3.15 > alpine-3.15.tar # 将tar拷贝到对应k8s主机 #kubernetes使用的镜像都在k8s.io命名空间中, 需要制定对应平台，如linux/amd64 $ ctr -n k8s.io images import alpine-3.15.tar --platform linux/amd64 unpacking docker.io/library/alpine:3.15 (sha256:69ba0f584ebec4ccf2ccf44817931f3facfb924380355466495274b2e273fe7b)...done # 可以看到镜像导入了 $ crictl images IMAGE TAG IMAGE ID SIZE docker.io/library/alpine 3.15 d51a1e6a80db9 5.87MB 。。。 从containerd导出、导入镜像 #导出镜像 ctr -n k8s.io images export alpine.tar docker.io/library/alpine:3.15 --platform linux/amd64 参考文档：https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/ https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/crictl/ https://docs.k3s.io/installation/private-registry "},"base/deployment_replicaset.html":{"url":"base/deployment_replicaset.html","title":"Deployment(部署)与 ReplicaSet(副本集)","keywords":"","body":"Deployment(部署)与 ReplicaSet(副本集) Deployment是对 ReplicaSet 和 Pod 更高级的抽象。 它使 Pod 拥有多副本，自愈，扩缩容、滚动升级等能力。 ReplicaSet(副本集)是一个 Pod 的集合。 它可以设置运行 Pod 的数量，确保任何时间都有指定数量的 Pod 副本在运行。 通常我们不直接使用 ReplicaSet，而是在 Deployment 中声明。 #创建deployment,部署3个运行nginx的Pod $ kubectl create deployment nginx-deploy --image=nginx:1.22 --replicas=3 #查看deployment(缩写成deploy) $ kubectl get deploy # 查看pod $ kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deploy-5964889c54-zmk6p 1/1 Running 0 6m1s nginx-deploy-5964889c54-th9f8 1/1 Running 0 6m1s nginx-deploy-5964889c54-28689 1/1 Running 0 6m1s #查看replicaSet(缩写为rs) $ kubectl get replicaSet NAME DESIRED CURRENT READY AGE nginx-deploy-5964889c54 3 3 3 7m13s 可以看到 5964889c54 为副本集 ， 有 3 个 pod 分别为 zmk6p、th9f8、28689 删除最后一个 pod 会再生成新的 pod $ kubectl delete pod nginx-deploy-5964889c54-28689 pod \"nginx-deploy-5964889c54-28689\" deleted # 可以看到生成了新的pod k9xnj，体现了 deploy 使pod拥有的自愈能力 $ kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deploy-5964889c54-zmk6p 1/1 Running 0 9m29s nginx-deploy-5964889c54-th9f8 1/1 Running 0 9m29s nginx-deploy-5964889c54-k9xnj 1/1 Running 0 13s 缩放 手动缩放 # 副本扩容到5个 $ kubectl scale deploy nginx-deploy --replicas=5 扩容过程 # DESIRED 目标 CURRENT 当前 READY 准备就绪 $ kubectl get rs --watch NAME DESIRED CURRENT READY AGE nginx-deploy-5964889c54 3 3 3 12m nginx-deploy-5964889c54 5 3 3 13m // Step A nginx-deploy-5964889c54 5 3 3 13m nginx-deploy-5964889c54 5 4 3 13m // Step B nginx-deploy-5964889c54 5 5 3 13m // Step C nginx-deploy-5964889c54 5 5 4 13m // Step D nginx-deploy-5964889c54 5 5 5 13m // Step E 可以看到在观测副本时过程 执行了扩容后 DESIRED 就变成了 5 (Step A) CURRENT 变成 4， 证明 启动了一个 pod，READY 还是 3， 说明还没启动完成 (Step B) CURRENT 变成 5， 证明 又启动了一个 pod，READY 还是 3， 说明还没启动完成 (Step C) READY 变成了 4， 说明成功运行了一个 pod (Step D) READY 变成了 5， 说明又成功运行了一个 pod, 这样 READY 和 DESIRED 相等，扩容完成 (Step D) 调整回去 $ kubectl scale deploy nginx-deploy --replicas=3 过程 $ kubectl get rs --watch NAME DESIRED CURRENT READY AGE nginx-deploy-5964889c54 5 5 5 27m nginx-deploy-5964889c54 3 5 5 28m nginx-deploy-5964889c54 3 5 5 28m nginx-deploy-5964889c54 3 3 3 28m 自动缩放 自动缩放通过增加和减少副本的数量，以保持所有 Pod 的平均 CPU 利用率不超过 75%。 自动伸缩需要声明 Pod 的资源限制，同时使用 Metrics Server 服务（K3s 默认已安装）。 本例仅用来说明kubectl autoscale命令的使用，完整示例参考：HPA演示 #自动缩放 kubectl autoscale deployment/nginx-auto --min=3 --max=10 --cpu-percent=75 #查看自动缩放 kubectl get hpa #删除自动缩放 kubectl delete hpa nginx-deployment 滚动更新 设置镜像为 1.23 $ kubectl set image deploy/nginx-deploy nginx=nginx:1.23 # 查看滚动更新状态 $ kubectl rollout status deployment/nginx-deploy deployment \"nginx-deploy\" successfully rolled out 查看更新后的版本和 pod $ kubectl get deploy/nginx-deploy -owide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx-deploy 3/3 3 3 39m nginx nginx:1.23 app=nginx-deploy 过程及说明 $ kubectl get rs --watch NAME DESIRED CURRENT READY AGE nginx-deploy-5964889c54 3 3 3 35m nginx-deploy-7c88b8c7c9 1 0 0 0s // Step 1 nginx-deploy-7c88b8c7c9 1 0 0 0s nginx-deploy-7c88b8c7c9 1 1 0 0s // Step 2 nginx-deploy-7c88b8c7c9 1 1 1 22s // Step 3 nginx-deploy-5964889c54 2 3 3 37m // Step 4 nginx-deploy-5964889c54 2 3 3 37m nginx-deploy-5964889c54 2 2 2 37m // Step 5 nginx-deploy-7c88b8c7c9 2 1 1 23s // Step 6 nginx-deploy-7c88b8c7c9 2 1 1 23s nginx-deploy-7c88b8c7c9 2 2 1 23s nginx-deploy-7c88b8c7c9 2 2 2 43s // Step 7 nginx-deploy-5964889c54 1 2 2 37m nginx-deploy-7c88b8c7c9 3 2 2 43s nginx-deploy-5964889c54 1 2 2 37m nginx-deploy-5964889c54 1 1 1 37m nginx-deploy-7c88b8c7c9 3 2 2 43s nginx-deploy-7c88b8c7c9 3 3 2 43s nginx-deploy-7c88b8c7c9 3 3 3 63s nginx-deploy-5964889c54 0 1 1 37m nginx-deploy-5964889c54 0 1 1 37m nginx-deploy-5964889c54 0 0 0 37m 可以看到 7c88b8c7c9 为新部署 nginx 的 deploy， 5964889c54 为 之前部署的 nginx 的 deploy step: 新 deploy 目标为 1 个 pod，当前和就绪为 0 新 deploy 1 个正在 启动 新 deploy 成功启动 1 个 旧 deploy 准备减少一个 旧 deploy 减少一个完成 新 deploy 准备再起 1 个 pod 新 deploy 成功又启动了 1 个 pod 后续步骤同理直到 新 deploy 满足要求 旧 deploy 停止所有 pod，副本集清 0 版本回滚 #查看历史版本 $ kubectl rollout history deployment/nginx-deploy deployment.apps/nginx-deploy REVISION CHANGE-CAUSE 1 2 # 查看版本1详情 5964889c54 为版本1 hash值 $ kubectl rollout history deployment/nginx-deploy --revision=1 deployment.apps/nginx-deploy with revision #1 Pod Template: Labels: app=nginx-deploy pod-template-hash=5964889c54 Containers: nginx: Image: nginx:1.22 Port: Host Port: Environment: Mounts: Volumes: #回滚到历史版本 $ kubectl rollout undo deployment/nginx-deploy --to-revision=1 deployment.apps/nginx-deploy rolled back 回滚过程 $ kubectl get rs --watch NAME DESIRED CURRENT READY AGE nginx-deploy-7c88b8c7c9 3 3 3 20m nginx-deploy-5964889c54 0 0 0 57m nginx-deploy-5964889c54 0 0 0 57m nginx-deploy-5964889c54 1 0 0 57m nginx-deploy-5964889c54 1 0 0 57m nginx-deploy-5964889c54 1 1 0 57m nginx-deploy-5964889c54 1 1 1 57m nginx-deploy-7c88b8c7c9 2 3 3 21m nginx-deploy-7c88b8c7c9 2 3 3 21m nginx-deploy-5964889c54 2 1 1 57m nginx-deploy-7c88b8c7c9 2 2 2 21m nginx-deploy-5964889c54 2 1 1 57m nginx-deploy-5964889c54 2 2 1 57m nginx-deploy-5964889c54 2 2 2 57m nginx-deploy-7c88b8c7c9 1 2 2 21m nginx-deploy-5964889c54 3 2 2 57m nginx-deploy-7c88b8c7c9 1 2 2 21m nginx-deploy-7c88b8c7c9 1 1 1 21m nginx-deploy-5964889c54 3 2 2 57m nginx-deploy-5964889c54 3 3 2 57m nginx-deploy-5964889c54 3 3 3 57m nginx-deploy-7c88b8c7c9 0 1 1 21m nginx-deploy-7c88b8c7c9 0 1 1 21m nginx-deploy-7c88b8c7c9 0 0 0 21m 查看回滚后的状态 # 查看副本集状态 $ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-deploy-5964889c54 3 3 3 59m nginx-deploy-7c88b8c7c9 0 0 0 22m # 查看pod状态，发现副本集回滚了 $ kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deploy-5964889c54-fkd8t 1/1 Running 0 2m31s nginx-deploy-5964889c54-lnd79 1/1 Running 0 2m30s nginx-deploy-5964889c54-tfdf7 1/1 Running 0 2m28s 删除无用副本集 $ kubectl delete rs nginx-deploy-7c88b8c7c9 replicaset.apps \"nginx-deploy-7c88b8c7c9\" deleted 参考文档：https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/replicaset/ https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/deployment/ https://kubernetes.io/zh-cn/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/ "},"base/service.html":{"url":"base/service.html","title":"Service(服务)","keywords":"","body":"Service(服务) Service 将运行在一组 Pods 上的应用程序公开为网络服务的抽象方法。 Service 为一组 Pod 提供相同的 DNS 名，并且在它们之间进行负载均衡。 Kubernetes 为 Pod 提供分配了 IP 地址，但 IP 地址可能会发生变化。 集群内的容器可以通过 service 名称访问服务，而不需要担心 Pod 的 IP 发生变化。 Kubernetes Service 定义了这样一种抽象： 逻辑上的一组可以互相替换的 Pod，通常称为微服务。 Service 对应的 Pod 集合通常是通过选择算符来确定的。 举个例子，在一个 Service 中运行了 3 个 nginx 的副本。这些副本是可互换的，我们不需要关心它们调用了哪个 nginx，也不需要关注 Pod 的运行状态，只需要调用这个服务就可以了。 # 查看所有 $ kubectl get all NAME READY STATUS RESTARTS AGE pod/nginx-deploy-5964889c54-fkd8t 1/1 Running 0 8m37s pod/nginx-deploy-5964889c54-lnd79 1/1 Running 0 8m36s pod/nginx-deploy-5964889c54-tfdf7 1/1 Running 0 8m34s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.43.0.1 443/TCP 4d12h NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/nginx-deploy 3/3 3 3 66m NAME DESIRED CURRENT READY AGE replicaset.apps/nginx-deploy-5964889c54 3 3 3 66m replicaset.apps/nginx-deploy-7c88b8c7c9 0 0 0 29m # 映射 pod 容器端口到服务器端口 $ kubectl expose deploy/nginx-deploy --name=nginx-service --port=8080 --target-port=80 service/nginx-service exposed # 查看service $ kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 443/TCP 4d12h nginx-service ClusterIP 10.43.146.225 8080/TCP 61s # 通过ip访问对应端口 $ wget -qO- http://10.43.146.225:8080 Welcome to nginx! html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } Welcome to nginx! If you see this page, the nginx web server is successfully installed and working. Further configuration is required. For online documentation and support please refer to nginx.org. Commercial support is available at nginx.com. Thank you for using nginx. 集群内部可以通过 service 名称+ 端口访问 # 创建一次性的内部pod 来测试 $ kubectl run test -ti --image=nginx:1.22 --rm -- bash If you don't see a command prompt, try pressing enter. # 测试访问内部 root@test:/# curl nginx-service:8080 Welcome to nginx! html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } Welcome to nginx! If you see this page, the nginx web server is successfully installed and working. Further configuration is required. For online documentation and support please refer to nginx.org. Commercial support is available at nginx.com. Thank you for using nginx. 查看 service 信息 # 可以看到对应IP 和 后端端点 $ kubectl describe service nginx-service Name: nginx-service Namespace: default Labels: app=nginx-deploy Annotations: Selector: app=nginx-deploy Type: ClusterIP IP Family Policy: SingleStack IP Families: IPv4 IP: 10.43.146.225 IPs: 10.43.146.225 Port: 8080/TCP TargetPort: 80/TCP Endpoints: 10.42.0.8:80,10.42.1.10:80,10.42.2.9:80 Session Affinity: None Events: # 获取pod信息 $ kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deploy-5964889c54-fkd8t 1/1 Running 0 23m nginx-deploy-5964889c54-lnd79 1/1 Running 0 23m nginx-deploy-5964889c54-tfdf7 1/1 Running 0 23m # 进入其中一个pod 并将首页改为 hello $ kubectl exec -ti nginx-deploy-5964889c54-tfdf7 -- bash root@nginx-deploy-5964889c54-tfdf7:/# cd /usr/share/nginx/html/ root@nginx-deploy-5964889c54-tfdf7:/usr/share/nginx/html# echo hello > index.html 退出后多访问几次 会出现 hello, 可见其采用了负载均衡技术 $ wget -qO- http://10.43.146.225:8080 hello 创建 Service 对象 想从集群外部访问服务就需要定义 service 类型 ServiceType 取值 ClusterIP：将服务公开在集群内部。kubernetes 会给服务分配一个集群内部的 IP，集群内的所有主机都可以通过这个 Cluster-IP 访问服务。集群内部的 Pod 可以通过 service 名称访问服务。如果不指定 ServiceType，其为莫仍类型 NodePort：通过每个节点的主机 IP 和静态端口（NodePort）暴露服务。 集群的外部主机可以使用节点 IP 和 NodePort 访问服务。 $ 暴露一个外部端口的服务 $ kubectl expose deploy/nginx-deploy --name=nginx-outside --type=NodePort --port=8081 --target-port=80 service/nginx-outside exposed / # kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 443/TCP 4d13h nginx-service ClusterIP 10.43.146.225 8080/TCP 18m nginx-outside NodePort 10.43.4.121 8081:32555/TCP 9s # 通过节点ip访问 $ curl 172.25.0.2:32555 hello $ curl 172.25.0.2:32555 Welcome to nginx! html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } Welcome to nginx! If you see this page, the nginx web server is successfully installed and working. Further configuration is required. For online documentation and support please refer to nginx.org. Commercial support is available at nginx.com. Thank you for using nginx. ExternalName：将集群外部的网络引入集群内部。 LoadBalancer：使用云提供商的负载均衡器向外部暴露服务。 访问 Service 前面 NodePort 访问主机：172.25.0.2:32555 1.NodePort端口是随机的，范围为:30000-32767。 2.集群中每一个主机节点的NodePort端口都可以访问。 3.如果需要指定端口，不想随机产生，需要使用配置文件来声明。 参考文档：https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/ https://kubernetes.io/zh-cn/docs/tutorials/stateless-application/expose-external-ip-address/ "},"base/namespace.html":{"url":"base/namespace.html","title":"Namespace(命名空间)","keywords":"","body":"Namespace(命名空间) 命名空间(Namespace)是一种资源隔离机制，将同一集群中的资源划分为相互隔离的组。 命名空间可以在多个用户之间划分集群资源（通过资源配额）。 例如我们可以设置开发、测试、生产等多个命名空间。 同一命名空间内的资源名称要唯一，但跨命名空间时没有这个要求。 命名空间作用域仅针对带有名字空间的对象，例如 Deployment、Service 等。 这种作用域对集群访问的对象不适用，例如 StorageClass、Node、PersistentVolume 等。 # 查看命名空间 缩写 ns $ kubectl get namespace NAME STATUS AGE default Active 4d15h kube-system Active 4d15h kube-public Active 4d15h kube-node-lease Active 4d15h Kubernetes 会创建四个初始命名空间： default 默认的命名空间，不可删除，未指定命名空间的对象都会被分配到 default 中。 kube-system Kubernetes 系统对象(控制平面和 Node 组件)所使用的命名空间。 kube-public 自动创建的公共命名空间，所有用户（包括未经过身份验证的用户）都可以读取它。通常我们约定，将整个集群中公用的可见和可读的资源放在这个空间中。 kube-node-lease 租约（Lease）对象使用的命名空间。每个节点都有一个关联的 lease 对象，lease 是一种轻量级资源。lease 对象通过发送心跳，检测集群中的每个节点是否发生故障。 使用 kubectl get lease -A 查看 lease 对象 kubenetes 的组件都运行在 kube-system 命名空间中, 自己部署的在 default 目录下 $ kubectl get pod -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system helm-install-traefik-crd-bjf84 0/1 Completed 0 4d15h kube-system helm-install-traefik-bcrr6 0/1 Completed 5 4d15h kube-system svclb-traefik-c090484e-hwms9 2/2 Running 2 (3d11h ago) 4d15h kube-system svclb-traefik-c090484e-4rlrg 2/2 Running 2 (3d11h ago) 4d15h kube-system coredns-77ccd57875-rf6s4 1/1 Running 10 (3d11h ago) 4d15h kube-system svclb-traefik-c090484e-cnsgm 2/2 Running 2 (3d11h ago) 4d15h kube-system local-path-provisioner-957fdf8bc-dw92l 1/1 Running 0 4d15h kube-system metrics-server-648b5df564-tnzrm 1/1 Running 30 (3d11h ago) 4d15h kube-system traefik-64f55bb67d-bhb49 1/1 Running 28 (3d11h ago) 4d15h default nginx-deploy-5964889c54-fkd8t 1/1 Running 0 152m default nginx-deploy-5964889c54-lnd79 1/1 Running 0 152m default nginx-deploy-5964889c54-tfdf7 1/1 Running 0 152m 新版本 apiserver 也是一个 lease 对象 $ kubectl get lease -A NAMESPACE NAME HOLDER AGE kube-node-lease k3d-demo-agent-0 k3d-demo-agent-0 4d15h kube-node-lease k3d-demo-agent-1 k3d-demo-agent-1 4d15h kube-node-lease k3d-demo-server-0 k3d-demo-server-0 4d15h kube-system apiserver-tbovar5ze2pqx4h6gvtcm557sm apiserver-tbovar5ze2pqx4h6gvtcm557sm_8167404a-b62f-45fb-81e8-72eddaf1aaf8 4d15h 使用多个命名空间 命名空间是在多个用户之间划分集群资源的一种方法（通过资源配额）。 例如我们可以设置开发、测试、生产等多个命名空间。 不必使用多个命名空间来分隔轻微不同的资源。 例如同一软件的不同版本： 应该使用标签 来区分同一命名空间中的不同资源。 命名空间适用于跨多个团队或项目的场景。 对于只有几到几十个用户的集群，可以不用创建命名空间。 命名空间不能相互嵌套，每个 Kubernetes 资源只能在一个命名空间中。 管理命名空间 #创建命名空间 $ kubectl create ns develop namespace/develop created #在命名空间内运行Pod --namespace 等价于 -n # kubectl run my-nginx --image=nginx -n=dev $ kubectl run nginx --image=nginx:1.22 --namespace=develop pod/nginx created #查看命名空间内的Pod $ kubectl get pod -n=develop NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 37s # 默认是 default 下的命名空间 $ kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deploy-5964889c54-fkd8t 1/1 Running 0 161m nginx-deploy-5964889c54-lnd79 1/1 Running 0 161m nginx-deploy-5964889c54-tfdf7 1/1 Running 0 161m 切换当前命名空间 $ kubectl config set-context $(kubectl config current-context) --namespace=develop # 默认命名空间就改变为 develop 了 $ kubectl get pod NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 3m25s 删除命名空间 $ kubectl delete ns develop namespace \"develop\" deleted # 因为默认被改为 develop 但现在develop 被删除了 $ kubectl get pod No resources found in develop namespace. # 查看ns状态 $ kubectl get ns NAME STATUS AGE default Active 4d15h kube-system Active 4d15h kube-public Active 4d15h kube-node-lease Active 4d15h # 切换为default $ kubectl config set-context $(kubectl config current-context) --namespace=default $ kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deploy-5964889c54-fkd8t 1/1 Running 0 6h6m nginx-deploy-5964889c54-lnd79 1/1 Running 0 6h6m nginx-deploy-5964889c54-tfdf7 1/1 Running 0 6h6m "},"base/declaration.html":{"url":"base/declaration.html","title":"声明式对象配置","keywords":"","body":"声明式对象配置 云原生的代表技术包括： 容器 服务网格 微服务 不可变基础设施 声明式API 管理对象 命令行指令 例如，使用 kubectl 命令来创建和管理 Kubernetes 对象。 命令行就好比口头传达，简单、快速、高效。 但它功能有限，不适合复杂场景，操作不容易追溯，多用于开发和调试。 声明式配置 kubernetes 使用 yaml 文件来描述 Kubernetes 对象。 声明式配置就好比申请表，学习难度大且配置麻烦。 好处是操作留痕，适合操作复杂的对象，多用于生产。 常用命令缩写 名称 缩写 Kind namespaces ns Namespace nodes no Node pods po Pod services srv Service deployments deploy Deployment replicasets rs ReplicaSet statefulsets sts StatefulSet YAML 规范 缩进代表上下级关系 缩进时不允许使用 Tab 键，只允许使用空格，通常缩进 2 个空格 : 键值对，后面必须有空格 -列表，后面必须有空格 [ ]数组 注释 | 多行文本块 ---表示文档的开始，多用于分割多个资源对象 group: s: 1 name: group-1 members: - name: \"Jack Ma\" UID: 10001 - name: \"Lei Jun\" UID: 10002 # comments words: [\"I don't care money\", \"R U OK\"] text: | line new line 3rd line # --- 多个资源对象的分隔 --- group: name: group-2 members: - name: \"Jack Ma\" UID: 10001 - name: \"Lei Jun\" UID: 10002 # comments words: [\"I don't care money\", \"R U OK\"] text: | line new line 3rd line 配置对象 在创建的 Kubernetes 对象所对应的 yaml 文件中，需要配置的字段如下： apiVersion - Kubernetes API 的版本 kind - 对象类别，例如 Pod、Deployment、Service、ReplicaSet 等 metadata - 描述对象的元数据，包括一个 name 字符串、UID 和可选的 namespace spec - 对象的配置 掌握程度： 不要求自己会写 找模版 能看懂 会修改 能排错 使用 yaml 定义一个Pod Pod 配置模版 apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: nginx:1.22 ports: - containerPort: 80 # 执行 $ kubectl apply -f my-pod.yaml pod/nginx created # 查看 nginx 创建了 $ kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deploy-5964889c54-fkd8t 1/1 Running 0 6h7m nginx-deploy-5964889c54-lnd79 1/1 Running 0 6h7m nginx-deploy-5964889c54-tfdf7 1/1 Running 0 6h7m nginx 1/1 Running 0 16s # 删除 $ kubectl delete -f my-pod.yaml pod \"nginx\" deleted 标签 标签（Labels） 是附加到对象（比如 Pod）上的键值对，用于补充对象的描述信息。 标签使用户能够以松散的方式管理对象映射，而无需客户端存储这些映射。 由于一个集群中可能管理成千上万个容器，我们可以使用标签高效的进行选择和操作容器集合。 键的格式： 前缀(可选)/名称(必须)。 有效名称和值： 必须为 63 个字符或更少（可以为空） 如果不为空，必须以字母数字字符（[a-z0-9A-Z]）开头和结尾 包含破折号-、下划线_、点.和字母或数字 label 配置模版 apiVersion: v1 kind: Pod metadata: name: label-demo labels: environment: production app: nginx spec: containers: - name: nginx image: nginx:1.22 ports: - containerPort: 80 $ kubectl apply -f label-pod.yaml pod/label-demo created $ kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deploy-5964889c54-fkd8t 1/1 Running 0 6h14m nginx-deploy-5964889c54-lnd79 1/1 Running 0 6h14m nginx-deploy-5964889c54-tfdf7 1/1 Running 0 6h14m label-demo 1/1 Running 0 5s # 显示标签 $ kubectl get pod --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-deploy-5964889c54-fkd8t 1/1 Running 0 6h14m app=nginx-deploy,pod-template-hash=5964889c54 nginx-deploy-5964889c54-lnd79 1/1 Running 0 6h14m app=nginx-deploy,pod-template-hash=5964889c54 nginx-deploy-5964889c54-tfdf7 1/1 Running 0 6h14m app=nginx-deploy,pod-template-hash=5964889c54 label-demo 1/1 Running 0 11s app=nginx,environment=production # -l 过滤 $ kubectl get pod -l \"app=nginx\" NAME READY STATUS RESTARTS AGE label-demo 1/1 Running 0 39s # , 分隔多个条件 $ kubectl get pod -l \"app=nginx,environment=production\" NAME READY STATUS RESTARTS AGE label-demo 1/1 Running 0 57s 选择器 标签选择器 可以识别一组对象。标签不支持唯一性。 标签选择器最常见的用法是为 Service 选择一组 Pod 作为后端。 Service 配置模版 apiVersion: v1 kind: Service metadata: name: my-service spec: type: NodePort selector: app: nginx ports: # 默认情况下，为了方便起见，`targetPort` 被设置为与 `port` 字段相同的值。 - port: 80 targetPort: 80 # 可选字段 # 默认情况下，为了方便起见，Kubernetes 控制平面会从某个范围内分配一个端口号 #（默认：30000-32767） nodePort: 30007 kubectl apply -f my-service.yaml service/my-service created $ kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 443/TCP 4d18h nginx-service ClusterIP 10.43.146.225 8080/TCP 6h9m nginx-outside NodePort 10.43.4.121 8081:32555/TCP 5h50m my-service NodePort 10.43.134.176 80:30007/TCP 4s $ kubectl describe svc/my-service Name: my-service Namespace: default Labels: Annotations: Selector: app=nginx Type: NodePort IP Family Policy: SingleStack IP Families: IPv4 IP: 10.43.134.176 IPs: 10.43.134.176 Port: 80/TCP TargetPort: 80/TCP NodePort: 30007/TCP Endpoints: 10.42.1.13:80 Session Affinity: None External Traffic Policy: Cluster Events: # 查看pod 是否被service 选中, 可以看到 Endpoints 对上 $ kubectl get pod -l \"app=nginx\" -owide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES label-demo 1/1 Running 0 10m 10.42.1.13 k3d-demo-agent-1 目前支持两种类型的选择运算：基于等值的和基于集合的。 多个选择条件使用逗号分隔，相当于 And(&&)运算。 等值选择 selector: matchLabels: # component=redis && version=7.0 component: redis version: 7.0 集合选择 selector: matchExpressions: # tier in (cache, backend) && environment not in (dev, prod) - { key: tier, operator: In, values: [cache, backend] } - { key: environment, operator: NotIn, values: [dev, prod] } 参考资料：https://kubernetes.io/zh-cn/docs/concepts/overview/working-with-objects/kubernetes-objects/ https://kubernetes.io/zh-cn/docs/concepts/overview/working-with-objects/object-management/ https://kubernetes.io/docs/reference/kubectl/#resource-types https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/ https://kubernetes.io/zh-cn/docs/concepts/overview/working-with-objects/labels/ "},"base/canary.html":{"url":"base/canary.html","title":"金丝雀发布","keywords":"","body":"金丝雀发布 金丝雀部署(canary deployment)也被称为灰度发布。 早期，工人下矿井之前会放入一只金丝雀检测井下是否存在有毒气体。 采用金丝雀部署，你可以在生产环境的基础设施中小范围的部署新的应用代码。 一旦应用签署发布，只有少数用户被路由到它，最大限度的降低影响。 如果没有错误发生，则将新版本逐渐推广到整个基础设施。 部署过程 部署第一个版本 发布 v1 版本的应用，镜像使用 nginx:1.22,数量为 3。 创建 Namespace Namespace 配置模版 创建 Deployment Deployment 配置模版 创建外部访问的 Service Service 配置模版 apiVersion: v1 kind: Namespace metadata: name: dev --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment-v1 namespace: dev labels: app: nginx-deployment-v1 spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.22 ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: name: canary-demo namespace: dev spec: type: NodePort selector: app: nginx ports: - port: 80 # By default and for convenience, the `targetPort` is set to # the same value as the `port` field. targetPort: 80 # Optional field # By default and for convenience, the Kubernetes control plane # will allocate a port from a range (default: 30000-32767) nodePort: 30008 $ kubectl apply -f deploy-v1.yaml namespace/dev created deployment.apps/nginx-deployment-v1 created service/canary-demo created $ kubectl get all -n=dev NAME READY STATUS RESTARTS AGE pod/nginx-deployment-v1-5467856d7c-dr89n 1/1 Running 0 8s pod/nginx-deployment-v1-5467856d7c-wctbv 1/1 Running 0 8s pod/nginx-deployment-v1-5467856d7c-xwqtv 1/1 Running 0 8s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/canary-demo NodePort 10.43.119.219 80:30008/TCP 8s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/nginx-deployment-v1 3/3 3 3 8s NAME DESIRED CURRENT READY AG # 获取service描述 $ kubectl describe service canary-demo -n=dev Name: canary-demo Namespace: dev Labels: Annotations: Selector: app=nginx Type: NodePort IP Family Policy: SingleStack IP Families: IPv4 IP: 10.43.119.219 IPs: 10.43.119.219 Port: 80/TCP TargetPort: 80/TCP NodePort: 30008/TCP Endpoints: 10.42.0.9:80,10.42.1.14:80,10.42.2.11:80 Session Affinity: None External Traffic Policy: Cluster Events: 创建 Canary Deployment 发布新版本的应用，镜像使用 docker/getting-started，数量为 1。 apiVersion: v1 kind: Namespace metadata: name: dev --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment-canary namespace: dev labels: app: nginx-deployment-canary spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: # 因为新部署的标签和原部署service选择的标签一样，所以部署后会自动加入原service app: nginx track: canary spec: containers: - name: new-nginx image: docker/getting-started ports: - containerPort: 80 $ kubectl apply -f deploy-canary.yaml namespace/dev unchanged deployment.apps/nginx-deployment-canary created $ kubectl get all -n=dev NAME READY STATUS RESTARTS AGE pod/nginx-deployment-v1-5467856d7c-dr89n 1/1 Running 0 17m pod/nginx-deployment-v1-5467856d7c-wctbv 1/1 Running 0 17m pod/nginx-deployment-v1-5467856d7c-xwqtv 1/1 Running 0 17m pod/nginx-deployment-canary-596dd6f965-8jfn4 1/1 Running 0 19s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/canary-demo NodePort 10.43.119.219 80:30008/TCP 17m NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/nginx-deployment-v1 3/3 3 3 17m deployment.apps/nginx-deployment-canary 1/1 1 1 19s NAME DESIRED CURRENT READY AGE replicaset.apps/nginx-deployment-v1-5467856d7c 3 3 3 17m replicaset.apps/nginx-deployment-canary-596dd6f965 1 1 1 19s # 访问成功 $ wget -qO- 10.43.119.219 Welcome to nginx! html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } Welcome to nginx! If you see this page, the nginx web server is successfully installed and working. Further configuration is required. For online documentation and support please refer to nginx.org. Commercial support is available at nginx.com. Thank you for using nginx. 分配流量 查看服务kubectl describe svc canary-demo --namespace=dev $ kubectl describe svc canary-demo -n=dev Name: canary-demo Namespace: dev Labels: Annotations: Selector: app=nginx Type: NodePort IP Family Policy: SingleStack IP Families: IPv4 IP: 10.43.119.219 IPs: 10.43.119.219 Port: 80/TCP TargetPort: 80/TCP NodePort: 30008/TCP Endpoints: 10.42.0.9:80,10.42.1.14:80,10.42.2.11:80 + 1 more... Session Affinity: None External Traffic Policy: Cluster Events: 上面 1 more... 表示新加入了一个节点 # 多次访问，直到出现以下表示部署成功 $ wget -qO- 10.43.119.219 var anchor=window.location.hash.substr(1);location.href=\"/tutorial/\"+(anchor?\"#\"+anchor:\"\")Getting Startedbody,input{font-family:\"Roboto\",\"Helvetica Neue\",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:\"Roboto Mono\",\"Courier New\",Courier,monospace} Getting Started Home &#xE5CD; Type to start searching docker/getting-started Getting Started docker/getting-started Getting Started Our Application Updating our App Sharing our App Persisting our DB Using Bind Mounts Multi-Container Apps Using Docker Compose Image Building Best Practices What Next? Home Copyright &copy; 2020-2022 Docker powered by MkDocs and Material for MkDocs 调整比例 待稳定运行一段时间后，扩大试用范围，将部署的 canary 版本数量调整为 3，v1 和 canary 的数量都是 3 个。 $ kubectl scale deploy nginx-deployment-canary --replicas=3 -n=devdeployment.apps/nginx-deployment-canary scaled ⚡ # 查看是否为3 $ kubectl get all -n=devNAME READY STATUS RESTARTS AGEpod/nginx-deployment-v1-5467856d7c-dr89n 1/1 Running 0 24mpod/nginx-deployment-v1-5467856d7c-wctbv 1/1 Running 0 24m pod/nginx-deployment-v1-5467856d7c-xwqtv 1/1 Running 0 24m pod/nginx-deployment-canary-596dd6f965-8jfn4 1/1 Running 0 7m47s pod/nginx-deployment-canary-596dd6f965-d7j92 0/1 ContainerCreating 0 10s pod/nginx-deployment-canary-596dd6f965-przpg 0/1 ContainerCreating 0 10s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/canary-demo NodePort 10.43.119.219 80:30008/TCP 24m NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/nginx-deployment-v1 3/3 3 3 24m deployment.apps/nginx-deployment-canary 1/3 3 1 7m47s NAME DESIRED CURRENT READY AGE replicaset.apps/nginx-deployment-v1-5467856d7c 3 3 3 24m replicaset.apps/nginx-deployment-canary-596dd6f965 3 3 1 7m47s 下线旧版本 最后下线所有 v1 版本，所有服务升级为 canary 版本。 kubectl scale deploy nginx-deployment-v1 --replicas=0 -n=dev deployment.apps/nginx-deployment-v1 scaled $ kubectl get all -n=dev NAME READY STATUS RESTARTS AGE pod/nginx-deployment-canary-596dd6f965-8jfn4 1/1 Running 0 10m pod/nginx-deployment-canary-596dd6f965-przpg 1/1 Running 0 2m28s pod/nginx-deployment-canary-596dd6f965-d7j92 1/1 Running 0 2m28s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/canary-demo NodePort 10.43.119.219 80:30008/TCP 27m NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/nginx-deployment-canary 3/3 3 3 10m deployment.apps/nginx-deployment-v1 0/0 0 0 27m NAME DESIRED CURRENT READY AGE replicaset.apps/nginx-deployment-canary-596dd6f965 3 3 3 10m replicaset.apps/nginx-deployment-v1-5467856d7c 0 0 0 27m 清空环境 $ kubectl delete all --all -n=dev pod \"nginx-deployment-canary-596dd6f965-8jfn4\" deleted pod \"nginx-deployment-canary-596dd6f965-przpg\" deleted pod \"nginx-deployment-canary-596dd6f965-d7j92\" deleted service \"canary-demo\" deleted deployment.apps \"nginx-deployment-v1\" deleted deployment.apps \"nginx-deployment-canary\" deleted replicaset.apps \"nginx-deployment-canary-596dd6f965\" deleted 局限性 按照 Kubernetes 默认支持的这种方式进行金丝雀发布，有一定的局限性： 不能根据用户注册时间、地区等请求中的内容属性进行流量分配 同一个用户如果多次调用该 Service，有可能第一次请求到了旧版本的 Pod，第二次请求到了新版本的 Pod 在 Kubernetes 中不能解决上述局限性的原因是：Kubernetes Service 只在 TCP 层面解决负载均衡的问题，并不对请求响应的消息内容做任何解析和识别。如果想要更完善地实现金丝雀发布，可以考虑 Istio 灰度发布。 参考文档： https://www.infoq.cn/article/lei4vsfpiw5a6en-aso4 https://kuboard.cn/learning/k8s-intermediate/workload/wl-deployment/canary.html "},"runapp/":{"url":"runapp/","title":"运行有状态的应用","keywords":"","body":"运行有状态应用 我们以 MySQL 数据库为例，在 kubernetes 集群中运行一个有状态的应用。 部署数据库几乎覆盖了 kubernetes 中常见的对象和概念： 配置文件--ConfigMap 保存密码--Secret 数据存储--持久卷(PV)和持久卷声明(PVC) 动态创建卷--存储类(StorageClass) 部署多个实例--StatefulSet 数据库访问--Headless Service 主从复制--初始化容器和 sidecar 数据库调试--port-forward 部署 Mysql 集群--helm "},"runapp/create_mysql.html":{"url":"runapp/create_mysql.html","title":"创建 MySQL 数据库","keywords":"","body":"创建 MySQL 数据库 配置环境变量 使用 MySQL 镜像 创建 Pod，需要使用环境变量设置 MySQL 的初始密码。 环境变量配置示例 挂载卷 将数据存储在容器中，一旦容器被删除，数据也会被删除。 将数据存储到卷(Volume)中，删除容器时，卷不会被删除。 hostPath 卷 hostPath 卷将主机节点上的文件或目录挂载到 Pod 中。 hostPath 配置示例 hostPath 的 type 值： DirectoryOrCreate DirectoryOrCreate Directory 挂载已存在目录。不存在会报错。 FileOrCreate 文件不存在则自动创建。不会自动创建文件的父目录，必须确保文件路径已经存在。 File 挂载已存在的文件。不存在会报错。 Socket 挂载 UNIX 套接字。例如挂载/var/run/docker.sock 进程 apiVersion: v1 kind: Pod metadata: name: mysql-pod labels: app: mysql spec: containers: - name: mysql image: mysql:5.7 env: - name: MYSQL_ROOT_PASSWORD value: \"123456\" volumeMounts: - mountPath: /var/lib/mysql name: data-volume volumes: - name: data-volume hostPath: # directory location on host path: /src/mysqldata # this field is optional type: DirectoryOrCreate 注意：hostPath 仅用于在单节点集群上进行开发和测试，不适用于多节点集群； 例如，当Pod被重新创建时，可能会被调度到与原先不同的节点上，导致新的Pod没有数据。 在多节点集群使用本地存储，可以使用local卷。 参考文档：https://kubernetes.io/zh-cn/docs/tasks/inject-data-application/define-environment-variable-container/ https://kubernetes.io/zh-cn/docs/concepts/storage/volumes/#hostpath https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-persistent-volume-storage/ "},"runapp/configmap_secret.html":{"url":"runapp/configmap_secret.html","title":"ConfigMap 与 Secret","keywords":"","body":"ConfigMap 与 Secret 在Docker中，我们一般通过绑定挂载的方式将配置文件挂载到容器里。 在Kubernetes集群中，容器可能被调度到任意节点，配置文件需要能在集群任意节点上访问、分发和更新。 ConfigMap ConfigMap 用来在键值对数据库(etcd)中保存非加密数据。一般用来保存配置文件。 ConfigMap 可以用作环境变量、命令行参数或者存储卷。 ConfigMap 将环境配置信息与 容器镜像 解耦，便于配置的修改。 ConfigMap 在设计上不是用来保存大量数据的。 在 ConfigMap 中保存的数据不可超过 1 MiB。 超出此限制，需要考虑挂载存储卷或者访问文件存储服务。 ConfigMap 用法 ConfigMap 配置示例 Pod 中使用 ConfigMap apiVersion: v1 kind: Pod metadata: name: mysql-pod labels: app: mysql spec: containers: - name: mysql image: mysql:5.7 env: - name: MYSQL_ROOT_PASSWORD value: \"123456\" volumeMounts: - mountPath: /var/lib/mysql name: data-volume - mountPath: /etc/mysql/conf.d name: conf-volume readOnly: true volumes: - name: conf-volume configMap: name: mysql-config - name: data-volume hostPath: # directory location on host path: /src/mysqldata # this field is optional type: DirectoryOrCreate --- apiVersion: v1 kind: ConfigMap metadata: name: mysql-config data: mysql.cnf: | [mysqld] character-set-server=utf8mb4 collation-server=utf8mb4_general_ci init-connect='SET NAMES utf8mb4' [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 # 获取对应键值信息， configMap 也可缩写为 cm $ kubectl describe configMap mysql-config Name: mysql-config Namespace: default Labels: Annotations: Data ==== mysql.cnf: ---- [mysqld] character-set-server=utf8mb4 collation-server=utf8mb4_general_ci init-connect='SET NAMES utf8mb4' [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 BinaryData ==== Events: # 获取信息 $ kubectl get pod -owide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES mysql-pod 1/1 Running 0 2m 10.42.1.5 k3d-demo-agent-1 # 进入mysql 查看字符集 $ kubectl exec -ti mysql-pod -- bash bash-4.2# mysql -uroot -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.43 MySQL Community Server (GPL) Copyright (c) 2000, 2023, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> show variables like \"%char%\" -> ; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8mb4 | | character_set_connection | utf8mb4 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | utf8mb4 | | character_set_server | utf8mb4 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.00 sec) 修改配置文件 $ kubectl edit cm mysql-config 在[client]上分增加一行注释 # this is a new comment, 查看配置文件已修改： $ kubectl exec -ti mysql-pod -- bash bash-4.2# cat /etc/mysql/conf.d/mysql.cnf [mysqld] character-set-server=utf8mb4 collation-server=utf8mb4_general_ci init-connect='SET NAMES utf8mb4' # this is a new comment [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 Secret Secret 用于保存机密数据的对象。一般由于保存密码、令牌或密钥等。 data 字段用来存储 base64 编码数据。 stringData 存储未编码的字符串。 Secret 意味着你不需要在应用程序代码中包含机密数据，减少机密数据(如密码)泄露的风险。 Secret 可以用作环境变量、命令行参数或者存储卷文件。 Secret 用法 Secret 配置示例 将 Secret 用作环境变量 $ echo -n '123456' | base64 MTIzNDU2 $ echo 'MTIzNDU2' | base64 --decode 123456 apiVersion: v1 kind: Secret metadata: name: mysql-password type: Opaque data: # 加密后的密码 PASSWORD: MTIzNDU2Cg== --- apiVersion: v1 kind: Pod metadata: name: mysql-pod labels: app: mysql spec: containers: - name: mysql image: mysql:5.7 env: - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: mysql-password key: PASSWORD optional: false # 表示不使用默认值 volumeMounts: - mountPath: /var/lib/mysql name: data-volume - mountPath: /etc/mysql/conf.d name: conf-volume readOnly: true volumes: - name: conf-volume configMap: name: mysql-config - name: data-volume hostPath: # directory location on host path: /src/mysqldata # this field is optional type: DirectoryOrCreate --- apiVersion: v1 kind: ConfigMap metadata: name: mysql-config data: mysql.cnf: | [mysqld] character-set-server=utf8mb4 collation-server=utf8mb4_general_ci init-connect='SET NAMES utf8mb4' [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 查看 secret $ kubectl apply -f mysql-pod_secret.yml secret/mysql-password created pod/mysql-pod created configmap/mysql-config configured $ kubectl describe secret/mysql-password Name: mysql-password Namespace: default Labels: Annotations: Type: Opaque Data ==== PASSWORD: 7 bytes "},"runapp/volume.html":{"url":"runapp/volume.html","title":"卷(Volume)","keywords":"","body":"卷(Volume) 将数据存储在容器中，一旦容器被删除，数据也会被删除。 卷是独立于容器之外的一块存储区域，通过挂载(Mount)的方式供 Pod 中的容器使用。 使用场景 卷可以在多个容器之间共享数据。 卷可以将容器数据存储在外部存储或云存储上。 卷更容易备份或迁移。 常见的卷类型 临时卷(Ephemeral Volume)： 与 Pod 一起创建和删除，生命周期与 Pod 相同 emptyDir - 作为缓存或存储日志 configMap 、secret、 downwardAPI - 给 Pod 注入数据 持久卷(Persistent Volume)： 删除 Pod 后，持久卷不会被删除 本地存储 - hostPath、 local 网络存储 - NFS 分布式存储 - Ceph(cephfs 文件存储、rbd 块存储) 投射卷(Projected Volumes)：projected 卷可以将多个卷映射到同一个目录上 后端存储 一个集群中可以包含多种存储(如 local、NFS、Ceph 或云存储)。 每种存储都对应一个存储类（StorageClass） ，存储类用来创建和管理持久卷，是集群与存储服务之间的桥梁。 管理员创建持久卷(PV)时，通过设置不同的 StorageClass 来创建不同类型的持久卷。 参考文档：https://kubernetes.io/zh-cn/docs/concepts/storage/volumes/ https://kubernetes.io/zh-cn/docs/concepts/storage/ephemeral-volumes/ https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-volume-storage/ "},"runapp/ev.html":{"url":"runapp/ev.html","title":"临时卷(EV)","keywords":"","body":"临时卷(EV) 临时卷(Ephemeral Volume) 与 Pod 一起创建和删除，生命周期与 Pod 相同 emptyDir - 初始内容为空的本地临时目录 configMap - 为 Pod 注入配置文件 secret - 为 Pod 注入加密数据 emptyDir emptyDir 会创建一个初始状态为空的目录，存储空间来自本地的 kubelet 根目录或内存(需要将 emptyDir.medium 设置为\"Memory\")。 通常使用本地临时存储来设置缓存、保存日志等。 例如，将 redis 的存储目录设置为 emptyDir apiVersion: v1 kind: Pod metadata: name: redis-pod spec: containers: - name: redis image: redis volumeMounts: - name: redis-storage mountPath: /data/redis volumes: - name: redis-storage emptyDir: {} configMap 卷和 secret 卷 注意：这里的 configMap 和 secret 代表的是卷的类型，不是 configMap 和 secret 对象。 删除 Pod 并不会删除 ConfigMap 对象和 secret 对象。 # 获取所有临时卷, 但得不到有效信息 $ kubectl get ev 。。。 查看临时卷 configMap 有效信息 # 获取pod UID $ kubectl get pods mysql-pod -o jsonpath='{.metadata.uid}' f49b79ac-e233-45fb-9928-967a55de6b43# $ cd /var/lib/kubelet/pods/ $ ls 66b1bd24-e020-4665-9c0a-f00c8d1eb15c 8aff060c-d1e8-4b17-87ff-8a820525cb34 93717d34-0df2-40db-905a-2929ac3e99b4 f49b79ac-e233-45fb-9928-967a55de6b43 # 进入临时卷 $ cd f49b79ac-e233-45fb-9928-967a55de6b43/volumes/kubernetes.io~configmap/conf-volume # 得到信息 $ cat mysql.cnf [mysqld] character-set-server=utf8mb4 collation-server=utf8mb4_general_ci init-connect='SET NAMES utf8mb4' [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 删除 pod 临时卷也被删除，但 configMap 对象依然存在 $ cd /var/lib/kubelet/pods $ ls 66b1bd24-e020-4665-9c0a-f00c8d1eb15c 8aff060c-d1e8-4b17-87ff-8a820525cb34 93717d34-0df2-40db-905a-2929ac3e99b4 f49b79ac-e233-45fb-9928-967a55de6b43 $ kubectl delete pod mysql-pod pod \"mysql-pod\" deleted # 被删除 $ ls 66b1bd24-e020-4665-9c0a-f00c8d1eb15c 8aff060c-d1e8-4b17-87ff-8a820525cb34 93717d34-0df2-40db-905a-2929ac3e99b4 # 看到configMap 依然存在 $ kubectl get cm NAME DATA AGE kube-root-ca.crt 1 69m mysql-config 1 52m 参考文档：https://kubernetes.io/zh-cn/docs/concepts/storage/volumes/ https://kubernetes.io/zh-cn/docs/concepts/storage/ephemeral-volumes/ https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-volume-storage/ "},"runapp/persistent_volume.html":{"url":"runapp/persistent_volume.html","title":"持久卷(PV)与持久卷声明(PVC)","keywords":"","body":"持久卷(PV)与持久卷声明(PVC) 持久卷(Persistent Volume)：删除 Pod 后，卷不会被删除 本地存储 hostPath - 节点主机上的目录或文件 (仅供单节点测试使用；多节点集群请用 local 卷代替) local - 节点上挂载的本地存储设备(不支持动态创建卷) 网络存储 NFS - 网络文件系统 (NFS) 分布式存储 Ceph(cephfs 文件存储、rbd 块存储) 持久卷(PV)和持久卷声明(PVC) 持久卷（PersistentVolume，PV） 是集群中的一块存储。可以理解为一块虚拟硬盘。 持久卷可以由管理员事先创建， 或者使用存储类（Storage Class）根据用户请求来动态创建。 持久卷属于集群的公共资源，并不属于某个 namespace; 持久卷声明（PersistentVolumeClaim，PVC） 表达的是用户对存储的请求。 PVC 声明好比申请单，它更贴近云服务的使用场景，使用资源先申请，便于统计和计费。 Pod 将 PVC 声明当做存储卷来使用，PVC 可以请求指定容量的存储空间和访问模式 。PVC 对象是带有 namespace 的。 创建持久卷（PV） 创建持久卷(PV)是服务端的行为，通常集群管理员会提前创建一些常用规格的持久卷以备使用。 hostPath 仅供单节点测试使用，当 Pod 被重新创建时，可能会被调度到与原先不同的节点上，导致新的 Pod 没有数据。多节点集群使用本地存储，可以使用 local 卷 创建 local 类型的持久卷，需要先创建存储类(StorageClass)。 本地存储类示例 # 创建本地存储类 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: local-storage provisioner: kubernetes.io/no-provisioner volumeBindingMode: Immediate local 卷不支持动态创建，必须手动创建持久卷(PV)。 创建 local 类型的持久卷，必须 设置 nodeAffinity(节点亲和性)。 调度器使用 nodeAffinity 信息来将使用 local 卷的 Pod 调度到持久卷所在的节点上，不会出现 Pod 被调度到别的节点上的情况。 注意：local卷也存在自身的问题，当Pod所在节点上的存储出现故障或者整个节点不可用时，Pod和卷都会失效，仍然会丢失数据，因此最安全的做法还是将数据存储到集群之外的存储或云存储上。 创建 PV PV 示例/local 卷示例 # 创建本地存储类 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: local-storage provisioner: kubernetes.io/no-provisioner volumeBindingMode: Immediate --- apiVersion: v1 kind: PersistentVolume metadata: name: local-pv-1 spec: capacity: storage: 1Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage #通过指定存储类来设置卷的类型 local: path: /mnt/disks/ssd1 nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: # - k8s-worker1 - k3d-demo-agent-1 进入 worker 节点创建文件夹 $ mkdir -p /mnt/disks/ssd1 进入主节点 $ kubectl apply -f local-storage-pv.yml storageclass.storage.k8s.io/local-storage created persistentvolume/local-pv-1 created 可以看到创建了一个 local 存储类和 pv 持久卷 查看持久卷 # 获取到信息，目前 声明CLAIM 为空 $ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE local-pv-1 1Gi RWO Delete Available local-storage 83s 创建持久卷声明(PVC) 持久卷声明(PVC)是用户端的行为,用户在创建 Pod 时，无法知道集群中 PV 的状态(名称、容量、是否可用等)，用户也无需关心这些内容，只需要在声明中提出申请，集群会自动匹配符合需求的持久卷(PV)。 Pod 使用持久卷声明(PVC)作为存储卷。 PVC 示例 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: local-pv-claim spec: storageClassName: local-storage # 与PV中的storageClassName一致 accessModes: - ReadWriteOnce resources: requests: storage: 1Gi # 创建了 pv claim对象 $ kubectl apply -f pvc.yaml persistentvolumeclaim/local-pv-claim created # local-pv-1 与前面声明一致 $ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE local-pv-claim Bound local-pv-1 1Gi RWO local-storage 62s # 可以看到绑定状态和类型都有了 $ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE local-pv-1 1Gi RWO Delete Bound default/local-pv-claim local-storage 7m41s 使用 PVC 作为卷 Pod 的配置文件指定了 PersistentVolumeClaim，但没有指定 PersistentVolume。 对 Pod 而言，PersistentVolumeClaim 就是一个存储卷。 PVC 卷示例 apiVersion: v1 kind: Secret metadata: name: mysql-password type: Opaque data: # 加密后的密码 PASSWORD: MTIzNDU2Cg== --- apiVersion: v1 kind: Pod metadata: name: mysql-pod labels: app: mysql spec: containers: - name: mysql image: mysql:5.7 env: - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: mysql-password key: PASSWORD optional: false # 表示不使用默认值 volumeMounts: - mountPath: /var/lib/mysql name: data-volume - mountPath: /etc/mysql/conf.d name: conf-volume readOnly: true volumes: - name: conf-volume configMap: name: mysql-config - name: data-volume persistentVolumeClaim: claimName: local-pv-claim # hostPath: # # directory location on host # path: /src/mysqldata # # this field is optional # type: DirectoryOrCreate --- apiVersion: v1 kind: ConfigMap metadata: name: mysql-config data: mysql.cnf: | [mysqld] character-set-server=utf8mb4 collation-server=utf8mb4_general_ci init-connect='SET NAMES utf8mb4' [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 绑定 创建持久卷声明(PVC)之后，集群会查找满足要求的持久卷(PV)，将 PVC 绑定到该 PV 上。 PVC 与 PV 之间的绑定是一对一的映射关系，绑定具有排他性，一旦绑定关系建立，该 PV 无法被其他 PVC 使用。 PVC 可能会匹配到比声明容量大的持久卷，但是不会匹配比声明容量小的持久卷。 例如，即使集群上存在多个 50 G 大小的 PV ，他们加起来的容量大于 100G，也无法匹配 100 G 大小的 PVC。 找不到满足要求的 PV ，PVC 会无限期地处于未绑定状态(Pending) , 直到出现了满足要求的 PV 时，PVC 才会被绑定。 访问模式 ReadWriteOnce 卷可以被一个节点以读写方式挂载，并允许同一节点上的多个 Pod 访问。 ReadOnlyMany 卷可以被多个节点以只读方式挂载。 ReadWriteMany 卷可以被多个节点以读写方式挂载。 ReadWriteOncePod 卷可以被单个 Pod 以读写方式挂载。 集群中只有一个 Pod 可以读取或写入该 PVC。 只支持 CSI 卷以及需要 Kubernetes 1.22 以上版本。 卷的状态 Available（可用）-- 卷是一个空闲资源，尚未绑定到任何； Bound（已绑定）-- 该卷已经绑定到某个持久卷声明上； Released（已释放）-- 所绑定的声明已被删除，但是资源尚未被集群回收； Failed（失败）-- 卷的自动回收操作失败。 **删除 pod 后，pod 中的持久卷声明和持久卷都不会被删除，需手动清除 # 删除pod $ kubectl delete pod mysql-pod pod \"mysql-pod\" deleted # pvc和pv还在 $ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE local-pv-claim Bound local-pv-1 1Gi RWO local-storage 19m # pv RECLAIM POLICY状态变为 Delete $ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE local-pv-1 1Gi RWO Delete Bound default/local-pv-claim local-storage 23m # 删除pvc $ kubectl delete pvc local-pv-claim persistentvolumeclaim \"local-pv-claim\" deleted $ kubectl get pvc No resources found in default namespace. $ pv状态failed $ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE local-pv-1 1Gi RWO Delete Failed default/local-pv-claim local-storage 24m # 删除pv $ kubectl delete pv local-pv-1 persistentvolume \"local-pv-1\" deleted $ kubectl get pv No resources found 卷模式 卷模式(volumeMode)是一个可选参数。 针对 PV 持久卷，Kubernetes 支持两种卷模式（volumeModes）： ● Filesystem（文件系统） 默认的卷模式。 ● Block（块） 将卷作为原始块设备来使用。 参考文档： https://kubernetes.io/zh-cn/docs/concepts/storage/volumes/ https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/ https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-persistent-volume-storage/ "},"runapp/storage_class.html":{"url":"runapp/storage_class.html","title":"存储类(StorageClass)","keywords":"","body":"存储类(StorageClass) 创建持久卷(PV) 静态创建 管理员预先手动创建 手动创建麻烦、不够灵活（local 卷不支持动态创建，必须手动创建 PV） 资源浪费（例如一个 PVC 可能匹配到比声明容量大的卷） 对自动化工具不够友好 动态创建 根据用户请求按需创建持久卷，在用户请求时自动创建 动态创建需要使用存储类（StorageClass） 用户需要在持久卷声明(PVC)中指定存储类来自动创建声明中的卷。 如果没有指定存储类，使用集群中默认的存储类。 存储类(StorageClass) 一个集群可以存在多个存储类（StorageClass）来创建和管理不同类型的存储。 每个 StorageClass 都有一个制备器（Provisioner），用来决定使用哪个卷插件创建持久卷。 该字段必须指定。 Local Path Provisioner kubectl get sc NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE local-path (default) rancher.io/local-path Delete WaitForFirstConsumer false 131m local-storage kubernetes.io/no-provisioner Delete Immediate false 35m K3s 自带了一个名为 local-path 的存储类(StorageClass)，它支持 动态创建 基于 hostPath 或 local 的持久卷。 创建 PVC 后，会自动创建 PV，不需要再去手动的创建 PV。 删除 PVC，PV 也会被自动删除。 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: local-pvc-1 namespace: default spec: accessModes: - ReadWriteOnce storageClassName: local-path resources: requests: storage: 1Gi 创建 localpath 声明 $ kubectl apply -f local-path-pvc.yaml persistentvolumeclaim/local-pvc-1 created $ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE local-pvc-1 Pending local-path 7s # 因为创建的localpath 绑定模式为 WaitForFirstConsumer，所以不会有pv $ kubectl get pv No resources found 卷绑定模式 volumeBindingMode 用于控制什么时候动态创建卷和绑定卷。 Immediate 立即创建 创建 PVC 后，立即创建 PV 并完成绑定。 WaitForFirstConsumer 延迟创建 当使用该 PVC 的 Pod 被创建时，才会自动创建 PV 并完成绑定。 使用 mysql-pod 绑定 localpath 的持久卷 apiVersion: v1 kind: Secret metadata: name: mysql-password type: Opaque data: # 加密后的密码 PASSWORD: MTIzNDU2Cg== --- apiVersion: v1 kind: Pod metadata: name: mysql-pod labels: app: mysql spec: containers: - name: mysql image: mysql:5.7 env: - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: mysql-password key: PASSWORD optional: false # 表示不使用默认值 volumeMounts: - mountPath: /var/lib/mysql name: data-volume - mountPath: /etc/mysql/conf.d name: conf-volume readOnly: true volumes: - name: conf-volume configMap: name: mysql-config - name: data-volume persistentVolumeClaim: claimName: local-pvc-1 # hostPath: # # directory location on host # path: /src/mysqldata # # this field is optional # type: DirectoryOrCreate --- apiVersion: v1 kind: ConfigMap metadata: name: mysql-config data: mysql.cnf: | [mysqld] character-set-server=utf8mb4 collation-server=utf8mb4_general_ci init-connect='SET NAMES utf8mb4' [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 $ kubectl apply -f mysql-pod_pvc_localpath.yml secret/mysql-password unchanged pod/mysql-pod created configmap/mysql-config unchanged # 可以看到绑定成功 $ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE local-pvc-1 Bound pvc-04601457-1ff9-4c53-9817-643e62fe01e2 1Gi RWO local-path 8m13s $ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pvc-04601457-1ff9-4c53-9817-643e62fe01e2 1Gi RWO Delete Bound default/local-pvc-1 local-path 29s 删除 pod 后 pvc 和 pv 不会被删除 $ kubectl delete pod mysql-pod pod \"mysql-pod\" deleted $ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE local-pvc-1 Bound pvc-04601457-1ff9-4c53-9817-643e62fe01e2 1Gi RWO local-path 11m $ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pvc-04601457-1ff9-4c53-9817-643e62fe01e2 1Gi RWO Delete Bound default/local-pvc-1 local-path 3m11s 删除 pvc 后 pv 会先释放，释放结束后清空资源 $ kubectl delete pvc local-pvc-1 persistentvolumeclaim \"local-pvc-1\" deleted $ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pvc-04601457-1ff9-4c53-9817-643e62fe01e2 1Gi RWO Delete Released default/local-pvc-1 local-path 3m47s $ kubectl get pv No resources found 回收策略（Reclaim Policy） 回收策略告诉集群，当用户删除 PVC 对象时， 从 PVC 中释放出来的 PV 将被如何处理。 ● 删除（Delete） 如果没有指定，默认为 Delete 当 PVC 被删除时，关联的 PV 对象也会被自动删除。 ● 保留（Retain） 当 PVC 对象被删除时，PV 卷仍然存在，数据卷状态变为\"已释放(Released)\"。 此时卷上仍保留有数据，该卷还不能用于其他 PVC。需要手动删除 PV。 参考文档： https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/ https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/#volume-binding-mode https://rancher.com/docs/k3s/latest/en/storage/ "},"runapp/stateful_set.html":{"url":"runapp/stateful_set.html","title":"StatefulSet(有状态应用集)","keywords":"","body":"StatefulSet(有状态应用集) StatefulSet 如果我们需要部署多个 MySQL 实例，就需要用到 StatefulSet。 StatefulSet 是用来管理有状态的应用。一般用于管理数据库、缓存等。 与 Deployment 类似， StatefulSet 用来管理 Pod 集合的部署和扩缩。 Deployment 用来部署无状态应用。StatefulSet 用来有状态应用。 创建 StatefulSet StatefulSet 配置模版 apiVersion: apps/v1 kind: StatefulSet metadata: name: mysql-sts spec: selector: matchLabels: app: mysql # 必须匹配 .spec.template.metadata.labels serviceName: \"mysql-svc\" replicas: 3 # 默认值是 1 minReadySeconds: 10 # 默认值是 0 template: metadata: labels: app: mysql # 必须匹配 .spec.selector.matchLabels spec: terminationGracePeriodSeconds: 10 containers: - name: mysql image: mysql:5.7 env: - name: MYSQL_ROOT_PASSWORD value: \"123456\" ports: - containerPort: 3306 volumeMounts: - mountPath: /var/lib/mysql #容器中的目录 name: data-volume volumeClaimTemplates: - metadata: name: data-volume spec: accessModes: [\"ReadWriteOnce\"] storageClassName: local-path resources: requests: storage: 1Gi 稳定的存储 在 StatefulSet 中使用 VolumeClaimTemplate，为每个 Pod 创建持久卷声明(PVC)。 每个 Pod 将会得到基于 local-path 存储类动态创建的持久卷(PV)。 Pod 创建(或重新调度）时，会挂载与其声明相关联的持久卷。 请注意，当 Pod 或者 StatefulSet 被删除时，持久卷声明和关联的持久卷不会被删除。 Pod 标识 在具有 N 个副本的 StatefulSet 中，每个 Pod 会被分配一个从 0 到 N-1 的整数序号，该序号在此 StatefulSet 上是唯一的。 StatefulSet 中的每个 Pod 主机名的格式为 StatefulSet 名称-序号。 上例将会创建三个名称分别为 mysql-0、mysql-1、mysql-2 的 Pod。 部署和扩缩保证 对于包含 N 个 副本的 StatefulSet，当部署 Pod 时，它们是依次创建的，顺序为 0..N-1。 当删除 Pod 时，它们是逆序终止的，顺序为 N-1..0。 在将扩缩操作应用到 Pod 之前，它前面的所有 Pod 必须是 Running 和 Ready 状态。 在一个 Pod 终止之前，所有的继任者必须完全关闭。 # 运行 $ kubectl apply -f statefulset.yaml statefulset.apps/mysql-sts created # 观察进度 $ kubectl get pod --watch NAME READY STATUS RESTARTS AGE mysql-sts-0 0/1 Pending 0 0s mysql-sts-0 0/1 Pending 0 17s mysql-sts-0 0/1 ContainerCreating 0 17s mysql-sts-0 1/1 Running 0 22s mysql-sts-1 0/1 Pending 0 0s mysql-sts-1 0/1 Pending 0 18s mysql-sts-1 0/1 ContainerCreating 0 19s mysql-sts-1 1/1 Running 0 35s mysql-sts-2 0/1 Pending 0 0s mysql-sts-2 0/1 Pending 0 16s mysql-sts-2 0/1 ContainerCreating 0 16s mysql-sts-2 1/1 Running 0 63s 在上面的 mysql 示例被创建后，会按照 mysql-0、mysql-1、mysql-2 的顺序部署三个 Pod。 在 mysql-0 进入 Running 和 Ready 状态前不会部署 mysql-1。 在 mysql-1 进入 Running 和 Ready 状态前不会部署 mysql-2。 如果 mysql-1 已经处于 Running 和 Ready 状态，而 mysql-2 尚未部署，在此期间发生了 mysql-0 运行失败，那么 mysql-2 将不会被部署，要等到 mysql-0 部署完成并进入 Running 和 Ready 状态后，才会部署 mysql-2。 如果用户想将示例中的 StatefulSet 扩缩为 replicas=1，首先被终止的是 mysql-2。 在 mysql-2 没有被完全停止和删除前，mysql-1 不会被终止。 当 mysql-2 已被终止和删除、mysql-1 尚未被终止，如果在此期间发生 mysql-0 运行失败， 那么就不会终止 mysql-1，必须等到 mysql-0 进入 Running 和 Ready 状态后才会终止 web-1。 参考文档：https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/statefulset/ https://kubernetes.io/zh-cn/docs/tasks/run-application/run-replicated-stateful-application/ "},"runapp/headless_service.html":{"url":"runapp/headless_service.html","title":"Headless Service(无头服务)","keywords":"","body":"Headless Service(无头服务) 之前我们创建了三个各自独立的数据库实例，mysql-0，mysql-1，mysql-2。 要想让别的容器访问数据库，我们需要将它发布为 Service，但是 Service 带负载均衡功能，每次请求都会转发给不同的数据库，这样子使用过程中会有很大的问题。 无头服务（Headless Services） 无头服务（Headless Service）可以为 StatefulSet 成员提供稳定的 DNS 地址。 在不需要负载均衡的情况下，可以通过指定 Cluster IP 的值为 \"None\" 来创建无头服务。 注意:StatefulSet中的ServiceName必须要跟Service中的metadata.name一致 # 为 StatefulSet 成员提供稳定的 DNS 表项的无头服务（Headless Service） apiVersion: v1 kind: Service metadata: #重要！这里的名字要跟后面StatefulSet里ServiceName一致 name: mysql-svc labels: app: mysql-svc spec: ports: - name: mysql port: 3306 # 设置Headless Service clusterIP: None selector: app: mysql --- apiVersion: apps/v1 kind: StatefulSet metadata: name: mysql-sts spec: selector: matchLabels: app: mysql # 必须匹配 .spec.template.metadata.labels serviceName: \"mysql-svc\" replicas: 3 # 默认值是 1 minReadySeconds: 10 # 默认值是 0 template: metadata: labels: app: mysql # 必须匹配 .spec.selector.matchLabels spec: terminationGracePeriodSeconds: 10 containers: - name: mysql image: mysql:5.7 env: - name: MYSQL_ROOT_PASSWORD value: \"123456\" ports: - containerPort: 3306 volumeMounts: - mountPath: /var/lib/mysql #容器中的目录 name: data-volume volumeClaimTemplates: - metadata: name: data-volume spec: accessModes: [\"ReadWriteOnce\"] storageClassName: local-path resources: requests: storage: 1Gi $ kubectl apply -f statefulset_headless.yaml service/mysql-svc created statefulset.apps/mysql-sts configured $ kubectl describe svc/mysql-svc Name: mysql-svc Namespace: default Labels: app=mysql-svc Annotations: Selector: app=mysql Type: ClusterIP IP Family Policy: SingleStack IP Families: IPv4 IP: None IPs: None Port: mysql 3306/TCP TargetPort: 3306/TCP Endpoints: 10.42.0.6:3306,10.42.1.8:3306,10.42.2.12:3306 Session Affinity: None Events: # 可以看到 CLUSTER-IP 为 None $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 443/TCP 177m mysql-svc ClusterIP None 3306/TCP 37s 稳定的网络 ID StatefulSet 中的每个 Pod 都会被分配一个 StatefulSet 名称-序号格式的主机名。 集群内置的 DNS 会为 Service 分配一个内部域名 db.default.svc.cluster.local,它的格式为 服务名称.命名空间.svc.cluster.local。 Service 下的每个 Pod 会被分配一个子域名，格式为 pod 名称.所属服务的域名，例如 mysql-0 的域名为 mysql-0.db.default.svc.cluster.local。 创建 Pod 时，DNS 域名生效可能会有一些延迟(几秒或几十秒)。 Pod 之间可以通过 DNS 域名访问，同一个命名空间下可以省略命名空间及其之后的内容。 查看主节点 host 文件 $ cat /etc/hosts # Kubernetes-managed hosts file. 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet fe00::0 ip6-mcastprefix fe00::1 ip6-allnodes fe00::2 ip6-allrouters 10.42.1.8 mysql-sts-0.mysql-svc.default.svc.cluster.local mysql-sts-0 新 pod 可以看到访问路由 $ kubectl run dns-test -ti --image=busybox:1.28 --rm If you don't see a command prompt, try pressing enter. / # nslookup mysql-svc Server: 10.43.0.10 Address 1: 10.43.0.10 kube-dns.kube-system.svc.cluster.local Name: mysql-svc Address 1: 10.42.0.6 mysql-sts-2.mysql-svc.default.svc.cluster.local Address 2: 10.42.1.8 mysql-sts-0.mysql-svc.default.svc.cluster.local Address 3: 10.42.2.12 mysql-sts-1.mysql-svc.default.svc.cluster.local / # nslookup mysql-sts-0.mysql-svc Server: 10.43.0.10 Address 1: 10.43.0.10 kube-dns.kube-system.svc.cluster.local Name: mysql-sts-0.mysql-svc Address 1: 10.42.1.8 mysql-sts-0.mysql-svc.default.svc.cluster.local 清除 $ kubectl delete -f statefulset_headless.yaml service \"mysql-svc\" deleted statefulset.apps \"mysql-sts\" deleted 参考文档： https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/statefulset/ https://kubernetes.io/zh-cn/docs/tutorials/stateful-application/basic-stateful-set/ https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/#headless-services https://kubernetes.io/zh-cn/docs/tasks/run-application/run-replicated-stateful-application/ https://kubernetes.io/zh-cn/docs/concepts/services-networking/dns-pod-service/ "},"runapp/mysql_replicate.html":{"url":"runapp/mysql_replicate.html","title":"Mysql 主从复制","keywords":"","body":"Mysql 主从复制 注意 1.本例子配置比较复杂，仅用于讲解原理，无需掌握配置细节。 2.后面我们会讲使用helm自动化部署，用起来非常简单。 3.本例子不能用于生产，mysql的密码允许设置为空。 下面是部署一个读写分离 Mysql 数据库的示意图。 通过部署无头服务(Headless Service)将写操作指向固定的数据库。 部署一个 Service 用来做读操作的负载均衡。 数据库之间通过同步程序保持数据一致。 Mysql 主从复制 运行一个有状态的应用程序 注意： 1.官方的安装文档有错误，mysql镜像需要使用mysql:5.7-debian。否则会出现如下错误： 详见： https://github.com/kubernetes/website/pull/35857 2.谷歌的镜像gcr.io/google-samples/xtrabackup:1.0访问不到，使用ist0ne/xtrabackup:1.0代替 apiVersion: v1 kind: ConfigMap metadata: name: mysql labels: app: mysql app.kubernetes.io/name: mysql data: primary.cnf: | # 仅在主服务器上应用此配置 [mysqld] log-bin replica.cnf: | # 仅在副本服务器上应用此配置 [mysqld] super-read-only --- # 为 StatefulSet 成员提供稳定的 DNS 表项的无头服务（Headless Service） apiVersion: v1 kind: Service metadata: name: mysql labels: app: mysql app.kubernetes.io/name: mysql spec: ports: - name: mysql port: 3306 clusterIP: None selector: app: mysql --- # 用于连接到任一 MySQL 实例执行读操作的客户端服务 # 对于写操作，你必须连接到主服务器：mysql-0.mysql apiVersion: v1 kind: Service metadata: name: mysql-read labels: app: mysql app.kubernetes.io/name: mysql readonly: \"true\" spec: ports: - name: mysql port: 3306 selector: app: mysql --- apiVersion: apps/v1 kind: StatefulSet metadata: name: mysql spec: selector: matchLabels: app: mysql app.kubernetes.io/name: mysql serviceName: mysql replicas: 3 template: metadata: labels: app: mysql app.kubernetes.io/name: mysql spec: initContainers: - name: init-mysql image: mysql:5.7-debian command: - bash - \"-c\" - | set -ex # 基于 Pod 序号生成 MySQL 服务器的 ID。 [[ $HOSTNAME =~ -([0-9]+)$ ]] || exit 1 ordinal=${BASH_REMATCH[1]} echo [mysqld] > /mnt/conf.d/server-id.cnf # 添加偏移量以避免使用 server-id=0 这一保留值。 echo server-id=$((100 + $ordinal)) >> /mnt/conf.d/server-id.cnf # 将合适的 conf.d 文件从 config-map 复制到 emptyDir。 if [[ $ordinal -eq 0 ]]; then cp /mnt/config-map/primary.cnf /mnt/conf.d/ else cp /mnt/config-map/replica.cnf /mnt/conf.d/ fi volumeMounts: - name: conf mountPath: /mnt/conf.d - name: config-map mountPath: /mnt/config-map - name: clone-mysql image: ist0ne/xtrabackup:1.0 command: - bash - \"-c\" - | set -ex # 如果已有数据，则跳过克隆。 [[ -d /var/lib/mysql/mysql ]] && exit 0 # 跳过主实例（序号索引 0）的克隆。 [[ `hostname` =~ -([0-9]+)$ ]] || exit 1 ordinal=${BASH_REMATCH[1]} [[ $ordinal -eq 0 ]] && exit 0 # 从原来的对等节点克隆数据。 ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql # 准备备份。 xtrabackup --prepare --target-dir=/var/lib/mysql volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d containers: - name: mysql image: mysql:5.7-debian env: - name: MYSQL_ALLOW_EMPTY_PASSWORD value: \"1\" ports: - name: mysql containerPort: 3306 volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d resources: requests: cpu: 500m memory: 1Gi livenessProbe: exec: command: [\"mysqladmin\", \"ping\"] initialDelaySeconds: 30 periodSeconds: 10 timeoutSeconds: 5 readinessProbe: exec: # 检查我们是否可以通过 TCP 执行查询（skip-networking 是关闭的）。 command: [\"mysql\", \"-h\", \"127.0.0.1\", \"-e\", \"SELECT 1\"] initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 1 - name: xtrabackup image: ist0ne/xtrabackup:1.0 ports: - name: xtrabackup containerPort: 3307 command: - bash - \"-c\" - | set -ex cd /var/lib/mysql # 确定克隆数据的 binlog 位置（如果有的话）。 if [[ -f xtrabackup_slave_info && \"x$( change_master_to.sql.in # 在这里要忽略 xtrabackup_binlog_info （它是没用的）。 rm -f xtrabackup_slave_info xtrabackup_binlog_info elif [[ -f xtrabackup_binlog_info ]]; then # 我们直接从主实例进行克隆。解析 binlog 位置。 [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1 rm -f xtrabackup_binlog_info xtrabackup_slave_info echo \"CHANGE MASTER TO MASTER_LOG_FILE='${BASH_REMATCH[1]}',\\ MASTER_LOG_POS=${BASH_REMATCH[2]}\" > change_master_to.sql.in fi # 检查我们是否需要通过启动复制来完成克隆。 if [[ -f change_master_to.sql.in ]]; then echo \"Waiting for mysqld to be ready (accepting connections)\" until mysql -h 127.0.0.1 -e \"SELECT 1\"; do sleep 1; done echo \"Initializing replication from clone position\" mysql -h 127.0.0.1 \\ -e \"$( 操作主库和从库 $ kubectl run mysql-client --image=arey/mysql-client -ti --rm -- mysql -h mysql-0.mysql If you don't see a command prompt, try pressing enter. MySQL [mysql]> CREATE DATABASE test; Query OK, 1 row affected (0.011 sec) MySQL [mysql]> CREATE TABLE test.messages (message VARCHAR(250)); Query OK, 0 rows affected (0.031 sec) MySQL [mysql]> INSERT INTO test.messages VALUES ('hello'); Query OK, 1 row affected (0.024 sec) MySQL [mysql]> SELECT * FROM test.messages; +---------+ | message | +---------+ | hello | +---------+ 1 row in set (0.001 sec) MySQL [mysql]> exit Bye Session ended, resume using 'kubectl attach mysql-client -c mysql-client -i -t' command when the pod is running pod \"mysql-client\" deleted # 登录从库，随机选择 $ kubectl run mysql-client --image=arey/mysql-client -ti --rm -- mysql -h mysql-read If you don't see a command prompt, try pressing enter. MySQL [mysql]> SELECT * FROM test.messages; +---------+ | message | +---------+ | hello | +---------+ 1 row in set (0.002 sec) # 可见从库是只读的，不能写入 MySQL [mysql]> INSERT INTO test.messages VALUES ('k8s'); ERROR 1290 (HY000): The MySQL server is running with the --super-read-only option so it cannot execute this statement 初始化容器(Init Containers) 初始化容器(Init Containers)是一种特殊容器，它在 Pod 内的应用容器启动之前运行。 初始化容器未执行完毕或以错误状态退出，Pod 内的应用容器不会启动。 初始化容器需要在 initContainers 中定义，与 containers 同级。 基于上面的特性，初始化容器通常用于 生成配置文件 执行初始化命令或脚本 执行健康检查（检查依赖的服务是否处于 Ready 或健康 Health 的状态） 在本例子中，有两个初始化容器。 init-mysql 为 MySQL 实例分配 server-id,并将 mysql-0 的配置文件设置为 primary.cnf,其他副本设置为 replica.cnf clone-mysql 从前一个 Pod 中获取备份的数据文件放到自己的数据目录下 边车 Sidecar Pod 中运行了 2 个容器，MySQL 容器和一个充当辅助工具的 xtrabackup 容器，我们称之为边车(sidecar)。 Xtrabackup 是一个开源的 MySQL 备份工具，支持在线热备份（备份时不影响数据读写），是目前各个云厂商普遍使用的 MySQL 备份工具。 sidecar 容器负责将备份的数据文件发送给下一个 Pod，并在副本服务器初次启动时，使用数据文件完成数据的导入。 MySQL 使用 bin-log 同步数据，但是，当数据库运行一段时间后，产生了一些数据，这时候如果我们进行扩容，创建了一个新的副本，有可能追溯不到 bin-log 的源头(可能被手动清理或者过期自动删除)，因此需要将现有的数据导入到副本之后，再开启数据同步，sidecar 只负责数据库初次启动时完成历史数据导入，后续的数据 MySQL 会自动同步。 客户端连接 写操作 写操作连接 mysql-0.mysql, 参考 操作主库和从库 读操作 读操作连接到mysql-read，它是一个service，会自动将请求负载均衡到后端的三个 mysql 实例上, 操作主库和从库 清空 $ kubectl delete -f mysql-cluster.yaml 参考文档： https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/init-containers/ https://kubernetes.io/zh-cn/docs/tasks/run-application/run-replicated-stateful-application/ 深入理解 StatefulSet:有状态应用实践 "},"runapp/port_forward.html":{"url":"runapp/port_forward.html","title":"Port-forward 端口转发","keywords":"","body":"Port-forward 端口转发 通常，集群中的数据库不直接对外访问。 但是，有时候我们需要图形化工具连接到数据库进行操作或者调试。 我们可以使用端口转发来访问集群中的应用。 kubectl port-forward 可以将本地端口的连接转发给容器。 此命令在前台运行，命令终止后，转发会话将结束。 这种类型的连接对数据库调试很有用。 $ kubectl port-forward pods/mysql-0 --address=172.29.0.2 33060:3306 Forwarding from 172.29.0.2:33060 -> 3306 Handling connection for 33060 在外部可以用 ip + 端口 访问了 $ kubectl run mysql-client --image=arey/mysql-client -ti --rm -- mysql -h 172.29.0.2 -P 33060 If you don't see a command prompt, try pressing enter. MySQL [mysql]> SHOW DATABASES; +------------------------+ | Database | +------------------------+ | information_schema | | mysql | | performance_schema | | sys | | test | | xtrabackup_backupfiles | +------------------------+6 rows in set (0.002 sec) 网络访问 容器中应用访问数据库： 读操作：mysql-read:3306 写操作：mysql-0.mysql:3306 集群中的 Node 访问： ClusterIP：port 集群外的主机访问： 主机 IP：nodePort 参考资料：https://kubernetes.io/zh-cn/docs/tasks/run-application/run-replicated-stateful-application/ https://kubernetes.io/zh-cn/docs/concepts/services-networking/dns-pod-service/ https://kubernetes.io/zh-cn/docs/tasks/access-application-cluster/port-forward-access-application-cluster/ "},"runapp/helm.html":{"url":"runapp/helm.html","title":"Helm安装MySQL机群","keywords":"","body":"Helm 安装 MySQL 机群 Helm 简介 Helm(http://helm.sh/) 是一个 Kubernetes 应用的包管理工具，类似于 Ubuntu 的 APT 和 CentOS 中的 YUM。 Helm 使用 chart 来封装 kubernetes 应用的 YAML 文件，我们只需要设置自己的参数，就可以实现自动化的快速部署应用。 安装 Helm 安装 Helm 下载安装包：https://github.com/helm/helm/releases https://get.helm.sh/helm-v3.10.0-linux-amd64.tar.gz mv linux-amd64/helm /usr/local/bin/helm 在 K3s 中使用，需要配置环境变量 export KUBECONFIG=/etc/rancher/k3s/k3s.yaml 三大概念 Chart 代表着 Helm 包。 它包含运行应用程序需要的所有资源定义和依赖，相当于模版。 类似于 maven 中的 pom.xml、Apt 中的 dpkb 或 Yum 中的 RPM。 Repository（仓库） 用来存放和共享 charts。 不用的应用放在不同的仓库中。 Release 是运行 chart 的实例。 一个 chart 通常可以在同一个集群中安装多次。 每一次安装都会创建一个新的 release，release name 不能重复。 Helm 仓库 Helm 有一个跟 docker Hub 类似的应用中心(https://artifacthub.io/)，我们可以在里面找到我们需要部署的应用。 安装单节点 Mysql 搜索 mysql 进入包名为 Bitnami的 chart INSTALL: 安装方式 VALUES SCHEMA: 常用参数 # 安装 $ helm install my-mysql --set-string auth.rootPassword=123456 --set primary.persistence.size=1Gi bitnami/mysql NAME: my-mysqlLAST DEPLOYED: Thu Oct 26 07:41:56 2023NAMESPACE: default STATUS: deployedREVISION: 1 TEST SUITE: None NOTES: CHART NAME: mysql CHART VERSION: 9.14.1 APP VERSION: 8.0.35 ** Please be patient while the chart is being deployed ** Tip: Watch the deployment status using the command: kubectl get pods -w --namespace default Services: echo Primary: my-mysql.default.svc.cluster.local:3306 Execute the following to get the administrator credentials: echo Username: root MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default my-mysql -o jsonpath=\"{.data.mysql-root-password}\" | base64 -d) To connect to your database: 1. Run a pod that you can use as a client: kubectl run my-mysql-client --rm --tty -i --restart='Never' --image docker.io/bitnami/mysql:8.0.35-debian-11-r0 --namespace default --env MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD --command -- bash 2. To connect to primary service (read/write): mysql -h my-mysql.default.svc.cluster.local -uroot -p\"$MYSQL_ROOT_PASSWORD\" # 查看设置 $ helm get values my-mysql USER-SUPPLIED VALUES: auth: rootPassword: \"123456\" primary: persistence: size: 1Gi # 删除本次 release $ helm delete my-mysql release \"my-mysql\" uninstalled 注意如果安装失败，需删除之前的 release 名称 # 同上面的delete $ helm uninstall my-mysql release \"my-mysql\" uninstalled 其他命令 #查看chart helm show chart bitnami/mysql #查看默认值 helm show values bitnami/mysql Helm 部署 MySQL 集群 安装过程中有两种方式传递配置数据： -f(或--values):使用 YAML 文件覆盖默认配置。可以指定多次，优先使用最右边的文件。 --set:通过命令行的方式对指定项进行覆盖。 如果同时使用两种方式，则 --set 中的值会被合并到 -f 中，但是 --set 中的值优先级更高。 使用配置文件设置 MySQL 的参数。 auth: rootPassword: \"123456\" # Primary database configuration primary: # Enable persistence using Persistent Volume Claims persistence: # 主节点持久卷大小 size: 1Gi # If true, use a Persistent Volume Claim, If false, use emptyDir enabled: true # Secondary database configuration secondary: # 设置从节点数量 replicaCount: 2 # Enable persistence using Persistent Volume Claims persistence: # 从节点持久卷大小 size: 1Gi # If true, use a Persistent Volume Claim, If false, use emptyDir enabled: true # 安装集群必须配置 architecture: replication 通过yaml问卷安装 $ helm install cluster -f values.yaml bitnami/mysql NAME: cluster LAST DEPLOYED: Thu Oct 26 07:56:15 2023 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: CHART NAME: mysql CHART VERSION: 9.14.1 APP VERSION: 8.0.35 ** Please be patient while the chart is being deployed ** Tip: Watch the deployment status using the command: kubectl get pods -w --namespace default Services: echo Primary: cluster-mysql-primary.default.svc.cluster.local:3306 echo Secondary: cluster-mysql-secondary.default.svc.cluster.local:3306 Execute the following to get the administrator credentials: echo Username: root MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default cluster-mysql -o jsonpath=\"{.data.mysql-root-password}\" | base64 -d) To connect to your database: 1. Run a pod that you can use as a client: kubectl run cluster-mysql-client --rm --tty -i --restart='Never' --image docker.io/bitnami/mysql:8.0.35-debian-11-r0 --namespace default --env MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD --command -- bash 2. To connect to primary service (read/write): mysql -h cluster-mysql-primary.default.svc.cluster.local -uroot -p\"$MYSQL_ROOT_PASSWORD\" 3. To connect to secondary service (read-only): mysql -h cluster-mysql-secondary.default.svc.cluster.local -uroot -p\"$MYSQL_ROOT_PASSWORD\" 获取创建过程 $ kubectl get pod --watch NAME READY STATUS RESTARTS AGE cluster-mysql-primary-0 0/1 ContainerCreating 0 2m33s cluster-mysql-secondary-0 0/1 Running 0 2m33s cluster-mysql-primary-0 0/1 Running 0 2m48s cluster-mysql-primary-0 0/1 Running 0 3m34s cluster-mysql-primary-0 1/1 Running 0 3m34s cluster-mysql-secondary-0 0/1 Running 1 (3s ago) 4m22s cluster-mysql-secondary-0 0/1 Running 1 (19s ago) 4m38s cluster-mysql-secondary-0 1/1 Running 1 (29s ago) 4m48s cluster-mysql-secondary-1 0/1 Pending 0 0s cluster-mysql-secondary-1 0/1 Pending 0 22s cluster-mysql-secondary-1 0/1 ContainerCreating 0 22s cluster-mysql-secondary-1 0/1 Running 0 2m9s $ kubectl get all NAME READY STATUS RESTARTS AGE pod/cluster-mysql-primary-0 1/1 Running 0 8m20s pod/cluster-mysql-secondary-0 1/1 Running 1 (4m1s ago) 8m20s pod/cluster-mysql-secondary-1 1/1 Running 0 3m32s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.43.0.1 443/TCP 25h service/cluster-mysql-primary-headless ClusterIP None 3306/TCP 8m20s service/cluster-mysql-secondary-headless ClusterIP None 3306/TCP 8m20s service/cluster-mysql-secondary ClusterIP 10.43.119.2 3306/TCP 8m20s service/cluster-mysql-primary ClusterIP 10.43.131.119 3306/TCP 8m20s NAME READY AGE statefulset.apps/cluster-mysql-primary 1/1 8m21s statefulset.apps/cluster-mysql-secondary 2/2 8m21s 以上可以看到分别为主从库创建了无头和有头的 service，主从库分别用 statefulset 创建 按照前面安装成功后说明操作： # 配置root用户密码环境变量 $ MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default cluster-mysql -o jsonpath=\"{.data.mysql-root-password}\" | base64 -d) # 创建mysql 客户端pod kubectl run cluster-mysql-client --rm --tty -i --restart='Never' --image docker.io/bitnami/mysql:8.0.35-debian-11-r0 --namespace default --env MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD --command -- bash If you don't see a command prompt, try pressing enter. I have no name!@cluster-mysql-client:/$ 在 pod 中连接主库测试 $ mysql -h cluster-mysql-primary.default.svc.cluster.local -uroot -p\"$MYSQL_ROOT_PASSWORD\" mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 133 Server version: 8.0.35 Source distribution Copyright (c) 2000, 2023, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> CREATE DATABASE test; Query OK, 1 row affected (0.07 sec) mysql> CREATE TABLE test.message (message VARCHAR(250)); Query OK, 0 rows affected (0.12 sec) mysql> INSERT INTO test.message VALUES ('hello'); Query OK, 1 row affected (0.05 sec) mysql> exit Bye 在 pod 中连接从库测试 $ mysql -h cluster-mysql-secondary.default.svc.cluster.local -uroot -p\"$MYSQL_ROOT_PASSWORD\" mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 159 Server version: 8.0.35 Source distribution Copyright (c) 2000, 2023, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> SELECT * FROM test.message; +---------+ | message | +---------+ | hello | +---------+ 1 row in set (0.02 sec) 参考文档： https://helm.sh/zh/docs/intro/install/ https://helm.sh/zh/docs/intro/using_helm/ "}}